- authors: "Donghyun Kim, Youbin Ahn, Wongyu Kim, Chanhee Lee, Kyungchan Lee, Kyong‐Ho Lee, Jeonguk Kim, Donghoon Shin(NCSOFT), Yeonsoo Lee(NCSOFT)"
  title: "Persona Expansion with Commonsense Knowledge for Diverse and Consistent Response Generation"
  conf: "The 17th Conference of the European Chapter of the Association for Computational Linguistics(EACL). (2023)"
  year: 2023
  abstract: "** abstract **"
  tags: ["EACL2023", "Dialogue", "NLP"]
  id: 0

- authors: "Donghyun Kim, Youbin Ahn, Chanhee Lee, Wongyu Kim, Kyong‐Ho Lee, Donghoon Shin(NCSOFT), Yeonsoo Lee(NCSOFT)"
  title: "Concept-based Persona Expansion for Improving Diversity of Persona-Grounded Dialogue"
  conf: "The 17th Conference of the European Chapter of the Association for Computational Linguistics(EACL). (2023)"
  year: 2023
  abstract: "** abstract **"
  tags: ["EACL2023", "Dialogue", "NLP"]
  id: 1

- authors: "Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo Lee(NCSOFT), Dong-Hoon Shin(NCSOFT), Seungryong Kim, Heuiseok Lim"
  title: "Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge"
  conf: "Proceedings of the AAAI Conference on Artificial Intelligence(AAAI). (2022)"
  year: 2022
  abstract: "Humans usually have conversations by making use of prior knowledge about a topic and background information of the people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive information, and thus they have a limitation in generating the utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge. To evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and GPT-2 as well as transformer-based models. We assess their generation abilities with automatic scores and conduct human evaluations for qualitative results. We examine whether the model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we show that the utterances of our data are constructed with the proper knowledge and persona through grounding quality assessment."
  tags: ["AAAI2022", "Dialogue", "NLP"]
  id: 2

- authors: "Sanghak Lee, Seungmin Seo, Byungkook Oh, Kyong-Ho Lee, Donghoon Shin(NCSOFT),Yeonsoo Lee(NCSOFT)"
  title: "Active Learning for Knowledge Graph Schema Expansion"
  conf: "IEEE Transactions on Knowledge and Data Engineering (TKDE), Vol. 32, Issue 12, pp. 5610-5620"
  year: 2022
  abstract: "Both entity typing and relation extraction from text corpora are widely used to identify the semantic types of an entity and a relation in a knowledge graph (KG). Most existing approaches rely on a pre-defined set of entity types and relation types in a KG. They thus cannot map entity mentions (relation mentions) to unseen entity types (relation types). To fundamentally overcome the limitations, we should add new semantic types of entities and relations to a KG schema. However, schema expansion traditionally requires manual conceptualization through a user’s observation on the text corpus while assuming the existence of suitable target KG schemas. In this work, we propose an A ctive learning framework for K nowledge graph S chema E xpansion ( AKSE ), which can generate a new semantic type for KG schemas, without depending on a set of target schemas and human users’ observation. Specifically, a granularity based active learning algorithm determines whether a KG schema requires new semantic types or not. We also introduce a KG schema attention-based neural method which assigns semantic types to the entities and relationships extracted. To the best of our knowledge, our work is the first study to expand a KG schema with active learning."
  tags: ["TKDE", "Search", "NLP"]
  id: 3

- authors: "Jungwoo Lim(Korea Univ), Myugnhoon Kang(Korea Univ), Yuna Hur(Korea Univ), Seung Won Jeong(Korea Univ), Jinsung Kim(Korea Univ), Yoonna Jang(Korea Univ), Dongyub Lee(NAVER), Hyesung Ji(NCSOFT), DongHoon Shin(NCSOFT), Seungryong Kim(Korea Univ) and Heuiseok Lim(Korea Univ)"
  title: "You Truly Understand What I Need: Intellectual and Friendly Dialogue Agents grounding Knowledge and Persona"
  conf: "The 2022 Conference on Empirical Methods in Natural Language Processing(EMNLP) (2022)"
  year: 2022
  abstract: "To build a conversational agent that interacts fluently with humans, previous studies blend knowledge or personal profile into the pre-trained language model. However, the model that considers knowledge and persona at the same time is still limited, leading to hallucination and a passive way of using personas. We propose an effective dialogue agent that grounds external knowledge and persona simultaneously. The agent selects the proper knowledge and persona to use for generating the answers with our candidate scoring implemented with a poly-encoder. Then, our model generates the utterance with lesser hallucination and more engagingness utilizing retrieval augmented generation with knowledge-persona enhanced query. We conduct experiments on the personaknowledge chat and achieve state-of-the-art performance in grounding and generation tasks on the automatic metrics. Moreover, we validate the answers from the models regarding hallucination and engagingness through human evaluation and qualitative results. We show our retriever’s effectiveness in extracting relevant documents compared to the other previous retrievers, along with the comparison of multiple candidate scoring methods. Code is available at https://github.com/dlawjddn803/INFO"
  tags: ["EMNLP2022", "Dialogue", "NLP"]
  id: 4

- authors: "Seonil Son (NCSOFT), Junsoo Park (NCSOFT), Jeong-in Hwang (NCSOFT), Junghwa Lee (NCSOFT), Hyungjong Noh (NCSOFT), Yeonsoo Lee (NCSOFT)"
  title: "HaRiM+: Evaluating Summary Quality with Hallucination Risk"
  conf: "AACL 2022"
  year: 2022
  abstract: "One of the challenges of developing a summarization model arises from the difficulty in measuring the factual inconsistency of the generated text. In this study, we reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries. We propose a reference-free metric, HaRiM+, which only requires an off-the-shelf summarization model to compute the hallucination risk based on token likelihoods. Deploying it requires no additional training of models or ad-hoc modules, which usually need alignment to human judgments. For summary-quality estimation, HaRiM+ records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits the use of summarization models, facilitates the progress of both automated evaluation and generation of summary."
  tags: ["AACL2022", "Translation", "NLP"]
  id: 5

- authors: "Hojun Cho (KAIST), Dohee Kim (KAIST), Seungwoo Ryu (KAIST), ChaeHun Park (KAIST), Hyungjong Noh (NCSOFT), Jeong-in Hwang (NCSOFT), Minseok Choi (KAIST), Edward Choi (KAIST), Jaegul Choo (KAIST)"
  title: "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model"
  conf: "The 2022 Conference on Empirical Methods in Natural Language Processing(EMNLP) (2022)"
  year: 2022
  abstract: "Style control, content preservation, and fluency determine the quality of text style transfer models. To train on a nonparallel corpus, several existing approaches aim to deceive the style discriminator with an adversarial loss. However, adversarial training significantly degrades fluency compared to the other two metrics. In this work, we explain this phenomenon using energy-based interpretation, and leverage a pretrained language model to improve fluency. Specifically, we propose a novel approach which applies the pretrained language model to the text style transfer framework by restructuring the discriminator and the model itself, allowing the generator and the discriminator to also take advantage of the power of the pretrained model. We evaluated our model on three public benchmarks GYAFC, Amazon, and Yelp and achieved state-of-the-art performance on the overall metrics."
  tags: ["EMNLP2022", "Translation", "NLP"]
  id: 6

- authors: "Eunhwan Park(JNU), Jong-Hyeon Lee(NCSOFT), Jeon Dong Hyeon(NAVER), Seonhoon Kim(NAVER), INHO KANG(NAVER) and Seung-Hoon Na(JNU)"
  title: "SISER: Semantic-Infused Selective Graph Reasoning for Fact Verification"
  conf: "Proceedings of the 29th International Conference on Computational Linguistics. (COLING) (2022)"
  year: 2022
  abstract: "This study proposes Semantic-Infused SElective Graph Reasoning (SISER) for fact verification, which newly presents semantic-level graph reasoning and injects its reasoning-enhanced representation into other
  types of graph-based and sequence-based reasoning methods. SISER combines three reasoning types: 1) semantic-level graph reasoning, which uses a semantic graph from evidence sentences, whose nodes are elements of a triple – <Subject, Verb, Object>, 2)“semantic-infused” sentence-level “selective” graph reasoning, which combine semanticlevel and sentence-level representations and perform graph reasoning in a selective manner using the node selection mechanism, and 3) sequence reasoning, which concatenates all evidence sentences and performs attentionbased reasoning. Experiment results on a large-scale dataset for Fact Extraction and VERification (FEVER) show that SISER outperforms the previous graph-based approaches and achieves state-of-the-art performance."
  tags: ["COLING2022", "Understanding", "NLP"]
  id: 7

- authors: "이정, 서민택, 나승훈, 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "자기지도학습 기반 음성 언어 모델을 이용한 자소 단위의 한국어 음성 인식"
  conf: "2022 한국소프트웨어종합학술대회"
  year: 2022
  abstract: "최근 다양한 산업 전반에서 자동 음성 인식(Automatic Speech Recognition)을 활용한 음성 기반의 인터페이스가 적용됨에 따라 높은 수준의 정확도를 보이는 음성 인식 기술에 대한 필요성이 점차 증대되고 있다. 하지만 음성 인식 분야에 대규모 사전 학습 모델을 활용하기 위해서는 음성 데이터와 함께 음성 전사 텍스트 데이터가 주석된 데이터(Labeled Data)가 필수적이나 대규모의 주석 데이터 구축에는 큰 비용이 소모된다는 단점이 존재한다. 따라서 본 논문에서는 주석 데이터에 대한 의존성을 줄이기 위하여 자기지도학습(Self-supervised Learning)에 기반한 사전 학습 음성 언어 모델을 바탕으로 한국어 음성 인식 모델을 구성하고 성능을 보인다."
  tags: ["2022한국소프트웨어종합학술대회", "Understanding", "NLP"]
  id: 8

- authors: "서민택, 나승훈, 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "한국어 음성인식 오류 교정을 위한 N-Best 결과 기반 생성 모델"
  conf: "2022 한국소프트웨어종합학술대회"
  year: 2022
  abstract: "성능 향상을 위한 많은 노력에도 불구하고 현재 Automatic Speech Recognition(ASR) 모델은 완벽하지 않기 때문에 실제 서비스에서 오류는 나타날 수밖에 없다. 서비스 품질 향상을 위해 이러한 오류 발생을 후처리를 통해 교정하려는 많은 노력이 진행되고 있다. 그러나 이러한 오류 유형중 고유명사 인식에서 오류가 발생하는 경우가 적지 않은데, 이러한 오류는 문장 자체로 본다면 정상이라 단일 단서로 교정하기가 어렵다. 이런 오류를 교정하기 위해서는 최상의 결과만을 활용하는 대신 상위 결과를 추가적으로 활용한다면 단서가 늘어나 올바른 단어로 교정할 확률이 증가한다. 따라서 본 논문에서는 생성 모델과 N-Best 결과를 이용한 간소화된 Ensemble 방법을 통해 교정 결과의 향상을 확인한다."
  tags: ["2022한국소프트웨어종합학술대회", "Understanding", "NLP"]
  id: 9

- authors: "이정, 서민택, 나승훈(전북대학교), 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "N-Best Re-ranking에 기반한 한국어 음성 인식 성능 개선"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "자동 음성 인식(Automatic Speech Recognition) 혹은 Speech-to-Text(STT)는 컴퓨터가 사람이 말하는 음성 언어를 텍스트 데이터로 전환하는 일련의 처리나 기술 등을 일컫는다. 음성 인식 기술이 다양한 산업 전반에 걸쳐 적용됨에 따라 높은 수준의 정확도와 더불어 다양한 분야에 적용할 수 있는 음성 인식 기술에 대한 필요성이 점차 증대되고 있다. 다만 한국어 음성 인식의 경우 기존 선행 연구에 비해 예사말/높임말의 구분이나 어미, 조사 등의 인식에 어려움이 있어 음성 인식 결과 후처리를 통한 성능 개선이 중요하다. 따라서 본 논문에서는 N-Best 음성 인식 결과가 구성되었을 때 Re-ranking을  통해 한국어 음성 인식의 성능을 개선하는 모델을 제안한다."
  tags: ["2022한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 10

- authors: "서민택, 나승훈(전북대학교), 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "문법성 품질 예측에 기반한 음성 인식 오류 교정"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "딥러닝의 발전 이후, 다양한 분야에서는 딥러닝을 이용해 이전에 어려웠던 작업들을 해결하여 사용자에게 편의성을 제공하고 있다. 하지만 아직 딥러닝을 통해 이상적인 서비스를 제공하는 데는 어려움이 있다. 특히, 음성 인식 작업에서 음성 양식에서 이용 방안에 대하여 다양성을 제공해주는 음성을 텍스트로 전환하는 Speech-To-Text(STT)은 문장 결과가 이상치에 달하지 못해 오류가 나타나게 된다. 본 논문에서는 STT 결과 보정을 문법 교정으로 치환하여 종단에서 올바른 토큰들을 조합하여 성능 향상을 하기 위해 각 토큰 별 품질 평가를 진행하는 모델을 한국어에서 적용하고 성능의 향상을 확인한다."
  tags: ["2022한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 11

- authors: "정민지(NCSOFT), 이새벽(NCSOFT), 김영준(NCSOFT), 허철훈(NCSOFT), 이충희(NCSOFT)"
  title: "오픈 도메인 질의응답을 위한 질문-구절의 밀집 벡터 표현 연구"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "질문에 답하기 위해 관련 구절을 검색하는 기술은 오픈 도메인 질의응답의 검색 단계를 위해 필요하다. 전통적인 방법은 정보 검색 기법인 빈도-역문서 빈도(TF-IDF) 기반으로 희소한 벡터 표현을 활용하여 구절을 검색한다. 하지만 희소 벡터 표현은 벡터 길이가 길 뿐만 아니라, 질문에 나오지 않는 단어나 토큰을 검색하지 못한다는 취약점을 가진다. 밀집 벡터 표현 연구는 이러한 취약점을 개선하고 있으며 대부분의 연구가 영어 데이터셋을 학습한 것이다. 따라서, 본 연구는 한국어 데이터셋을 학습한 밀집 벡터 표현을 연구하고 여러 가지 부정 샘플(negative sample) 추출 방법을 도입하여 전이 학습한 모델 성능을 비교 분석한다. 또한, 대화 응답 선택 태스크에서 밀집 검색에 활용한 순위 재지정 상호작용 레이어를 추가한 실험을 진행하고 비교 분석한다. 밀집 벡터 표현 모델을 학습하는 것이 도전적인 과제인만큼 향후에도 다양한 시도가 필요할 것으로 보인다."
  tags: ["2022한글및한국어정보처리학술대회", "Search", "NLP"]
  id: 12

- authors: "Byung-Chull Bae(hongik univ.) Suji Jang(hongik univ), Youngjune Kim(NCSOFT), Seyoung Park(NCSOF)"
  title: "A Preliminary Survey on Story Interestingness: Focusing on Cognitive and Emotional Interest"
  conf: "ICIDS 2021"
  year: 2021
  abstract: "Story interestingness is of great importance in narrative understanding and generation. In this paper, based on the outlined literature review, we present our incipient framework for measuring story interestingness, consisting of two factors - cognitive interest and emotional interest. The cognitive factors include four components - goal, novelty, inference, and schema violation. The emotional aspects contain four elements - empathy, external emotions, humor, and outcome valence."
  tags: ["ICIDS2021", "Data", "NLP"]
  id: 13

- authors: "정영준 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "비지도 기계 번역을 이용한 한국어 채팅체 문체 변환"
  conf: "2021 한국컴퓨터종합학술대회"
  year: 2021
  abstract: "문체 변환(style transfer)은 소스 문체(source style)로 쓰여진 텍스트가 주어지면 내용(content)을 유지하면서 타겟 문체(target style)의 텍스트를 생성하는 작업이다. 일반적으로 내용은 불변성(invariance), 문체는 가변성(variance)이라고 가정하여 텍스트의 문체를 변환하게 된다. 하지만, 채팅체의 경우 내용과 문체의 경계가 모호한 특성을 가지기 때문에 분리에 어려움이 있어 기존의 문체 변환 모델로 학습이 잘 되지 않는 문제가 있다. 본 논문에서는 비지도 기계 번역(unsupervised machine translation)을 이용한 문체 변환 모델을 사용하여 채팅체를 문어체로 변환하는 방법을 제안한다. 또한, 변환된 결과를 활용하여 문체 변환에 사용될 수 있는 문체 간 단어 변환 사전을 구축할 수 있음을 보인다."
  tags: ["2021한국컴퓨터종합학술대회", "문체변환", "Translation", "NLP"]
  id: 14

- authors: "민주 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "채팅체-문어체 스타일 변환 병렬 코퍼스 자동 구축"
  conf: "2021 한국컴퓨터종합학술대회"
  year: 2021
  abstract: "인터넷 채팅체로 쓰여진 문장은 문어체 문장과 달리 신조어 및 축약어가 쓰이며 문체 또한 일반적인 문어체 또는 구어체와 상이하다. 따라서 인터넷 채팅체를 기존 문어체 기반 자연어처리 시스템에서 이용하기 위해서는 채팅체-문어체 스타일 변환 기술이 필요하며, 이를 위해서 구어체-문어체로 이루어진 병렬 코퍼스를 구축할 필요가 있다. 본 논문에서는 채팅체 문장을 문어체로 변환한 문장 쌍 병렬 코퍼스를 Round-Trip Translation 기법을 이용하여 자동으로 구축하고, 자동으로 구축된 병렬 코퍼스 중에 부정확한 문장 쌍을 자동으로 필터링하는 방법을 제안한다. 또한 구축된 병렬 코퍼스를 검증하기 위해 구축된 병렬 코퍼스를 이용하여 자동으로 채팅체-문어체 변환 사전을 구축하였다."
  tags: ["2021한국컴퓨터종합학술대회", "Translation", "NLP"]
  id: 15

- authors: "배장성 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "마스크 언어 모델 기반 비병렬 한국어 텍스트 스타일 변환"
  conf: "2021 한글및한국어정보처리 학술대회"
  year: 2021
  abstract: "텍스트 스타일 변환은 입력 스타일(source style)로 쓰여진 텍스트의 내용(content)을 유지하며 목적 스타일(target style)의 텍스트로 변환하는 문제이다. 텍스트 스타일 변환을 시퀀스 간 변환 문제(sequence-to-sequence)로 보고 기존 기계학습 모델을 이용해 해결할 수 있지만, 모델 학습에 필요한 각 스타일에 대응되는 병렬 말뭉치를 구하기 어려운 문제점이 있다. 따라서 최근에는 비병렬 말뭉치를 이용해 텍스트 스타일 변환을 수행하는 방법들이 연구되고 있다. 이 연구들은 주로 인코더-디코더 구조의 생성 모델을 사용하기 때문에 입력 문장이 가지고 있는 내용이 누락되거나 다른 내용의 문장이 생성될 수 있는 문제점이 있다. 본 논문에서는 마스크 언어 모델(masked language model)을 이용해 입력 텍스트의 내용을 유지하면서 원하는 스타일로 변경할 수 있는 텍스트 스타일 변환 방법을 제안하고 한국어 긍정-부정, 채팅체-문어체 변환에 적용한다."
  tags: ["2021한글및한국어정보처리학술대회", "Translation", "NLP"]
  id: 16

- authors: "박진솔(서울대학교), 최맹식(NCSOFT), Andrew Matteson(NCSOFT), 이충희(NCSOFT)"
  title: "생략복원을 위한 ELECTRA 기반 모델 최적화 연구"
  conf: "2021 한글및한국어정보처리 학술대회"
  year: 2021
  abstract: "한국어에서는 문장 내의 주어나 목적어가 자주 생략된다. 자연어 처리에서 이러한 문장을 그대로 사용하는 것은 정보 부족으로 인한 문제 난이도 상승으로 귀결된다. 생략복원은 텍스트에서 생략된 부분을 이전 문구에서 찾아서 복원해 주는 기술이며, 본 논문은 생략된 주어를 복원하는 방법에 대한 연구이다. 본 논문에서는 기존에 생략복원에 사용되지 않았던 다양한 입력 형태를 시도한다. 또한, 출력 레이어로는 finetuning layer(Linear, Bi-LSTM, MultiHeadAttention)와 생략복원 태스크 형태(BIO tagging, span prediction)의 다양한 조합을 실험한다. 국립국어원 무형 대용어 복원 말뭉치를 기반으로 생략복원이 불필요한 네거티브 샘플을 추가하여 ELECTRA 기반의 딥러닝 생략복원 모델을 학습시키고, 생략복원에 최적화된 조합을 검토한다."
  tags: ["2021한글및한국어정보처리학술대회", "Translation", "NLP"]
  id: 17

- authors: "Hyonsu Choe(NCSOFT), Jiyoon Han(YU), Hyejin Park(YU), Tae Hwan Oh(YU), Hansaem Kim(YU)"
  title: "Building Korean Abstract Meaning Representation Corpus"
  conf: "Proceedings of DMR 2020"
  year: 2020
  abstract: "To explore the potential sembanking in Korean and ways to represent the meaning of Korean sentences, this paper reports on the process of applying Abstract Meaning Representation to Korean, a semantic representation framework that has been studied in wide range of languages, and its output: the Korean AMR corpus. The corpus which is constructed so far is a size of 1,253 sentences and its raw texts are from ExoBrain Corpus, a state-led R&D project on language AI. This paper also analyzes the result in both qualitative and quantitative manners, proposing discussions for further development."
  tags: ["ProceedingsofDMR2020", "Data", "NLP"]
  id: 18

- authors: "신승우 (NCSOFT), 오주민 (NCSOFT), 노형종 (NCSOFT), 이연수 (NCSOFT)"
  title: "Sent2dl : 기술논리 SROIQ 기반 기호적 문장 의미 표상에 분산 표상 더하기"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "기존의 자연어 의미 표상 방법은 크게 나눠보았을 때 두 가지가 있다. 첫 번째로, 전통적인 기호 기반 의미 표상 방법론이다. 이 방법론들은 논리적이고 해석가능하다는 장점이 있으나, 구축에 시간이 많이 들고 정작 기호 자체의 의미를 더욱 미시적으로 파악하기 어렵다는 단점이 있었다. 반면, 최근 대두된 분산 표상의 경우 단어 하나하나의 의미는 상대적으로 잘 파악하는 반면, 문장 등의 복잡한 구조의 의미를 나타내는 데 있어 상대적으로 약한 측면을 보이며 해석가능하지 않다는 단점이 있다. 본 논문에서는 이 둘의 장점을 섞어서 서로의 단점을 보완하는 새로운 의미 표상을 제안하였으며, 이 표상이 유의미하게 문장의 의미를 담고 있음을 비지도 문장 군집화 문제를 통해 간접적으로 보였다."
  tags: ["2020한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 19

- authors: "이진우(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT)"
  title: "의존 구문 분석에 손실 함수가 미치는 영향: 한국어 Left-To-Right Parser를 중심으로"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "본 연구는 딥 러닝 기반 의존 구문 분석에서, 학습에 적용하는 손실 함수에 따른 성능을 평가하였다. Pointer Network를 이용한 Left-To-Right 모델을 총 세 가지의 손실 함수(Maximize Golden Probability, Cross Entropy, Local Hinge)를 이용하여 학습시켰다. 그 결과 LH 손실 함수로 학습한 모델이 선행 연구와 같이 MGP 손실 함수로 학습한 것에 비해 UAS/LAS가 각각 0.86%p/0.87%p 상승하였으며, 특히 의존 거리가 먼 경우에 대하여 분석 성능이 크게 향상됨을 확인하였다. 딥러닝 의존 구문 분석기를 구현할 때 학습 모델과 입력 표상뿐만 아니라 손실 함수 역시 중요하게 고려되어야 함을 보였다."
  tags: ["2020한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 20

- authors: "최현수(NCSOFT), 민진우, 나승훈(전북대학교), 김한샘(연세대학교)"
  title: "국어 의미 자원 구축 및 의미 파싱을 위한 Korean AMR 데이터 자동 증강"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "본 연구에서는 한국어 의미 표상 자원 구축과 의미 파싱 성능 향상을 위한 데이터 자동 증강 방법을 제안하고 수동 구축 결과 대비 자동 변환 정확도를 보인다. 지도 학습 기반의 AMR 파싱 모델이 유의미한 성능에 도달하려면 대량의 주석 데이터가 반드시 필요하다. 본 연구에서는 기성 언어 분석 기술 또는 기존에 구축된 말뭉치의 주석 정보를 바탕으로 Semi-AMR 데이터를 변환해내는 알고리즘을 제시하며, 자동 변환 결과는 Gold-standard 데이터에 대해 Smatch F1 0.46의 일치도를 보였다. 일정 수준 이상의 정확도를 보이는 자동 증강 데이터는 주석 프로젝트에 소요되는 비용을 경감시키는 데에 활용될 수 있다."
  tags: ["2020한글및한국어정보처리학술대회", "Data", "NLP"]
  id: 21

- authors: "이민호(NCSOFT), 최맹식(NCSOFT), 김정아(NCSOFT), 이충희(NCSOFT), 김보희(NCSOFT), 오효정(전북대학교), 이연수(NCSOFT)"
  title: "키워드 추출용 구묶음 데이터 구축 및 개선 방법 연구"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "구묶음은 문장을 겹치지 않는 문장 구성 성분으로 나누는 과정으로, 구묶음 방법에 따라 구문분석, 관계추출 등 다양한 하위 태스크에 사용할 수 있다. 본 논문에서는 문장의 키워드를 추출하기 위한 구묶음 방식을 제안하고, 키워드 단위 구묶음 데이터를 구축하기 위한 가이드라인을 제작하였다. 해당 가이드라인을 적용하여 구축한 데이터와 BERT 기반의 모델을 이용하여 학습 및 평가를 통해 구축된 데이터의 품질을 측정하여 78점의 F1점수를 얻었다. 이후 패턴 통일, 형태소 표시 여부 등 다양한 개선 방법의 적용 및 재실험을 통해 가이드라인의 개선 방향을 제시한다."
  tags: ["2020한글및한국어정보처리학술대회", "Data", "NLP"]
  id: 22

- authors: "Hyesung Ji(NCSOFT), Danial Hooshyar, Kuekyeng Kim, and Heuiseok Lim (Korea univ)"
  title: "A semantic-based video scene segmentation using a deep neural network"
  conf: "Journal of Information Science 45(6)"
  year: 2019
  abstract: "Video scene segmentation is very important research in the field of computer vision, because it helps in efficient storage, indexing and retrieval of videos. Achieving this kind of scene segmentation cannot be done by just calculating the similarity of low-level features presented in the video; high-level features should also be considered to achieve a better performance. Even though much research has been conducted on video scene segmentation, most of these studies failed to semantically segment a video into scenes. Thus, in this study, we propose a Deep-learning Semantic-based Scene-segmentation model (called DeepSSS) that considers image captioning to segment a video into scenes semantically. First, the DeepSSS performs shot boundary detection by comparing colour histograms and then employs maximum-entropy-applied keyframe extraction. Second, for semantic analysis, using image captioning that benefits from deep learning generates a semantic text description of the keyframes. Finally, by comparing and analysing the generated texts, it assembles the keyframes into a scene grouped under a semantic narrative. That said, DeepSSS considers both low- and high-level features of videos to achieve a more meaningful scene segmentation. By applying DeepSSS to data sets from MS COCO for caption generation and evaluating its semantic scene-segmentation task results with the data sets from TRECVid 2016, we demonstrate quantitatively that DeepSSS outperforms other existing scene-segmentation methods using shot boundary detection and keyframes. What’s more, the experiments were done by comparing scenes segmented by humans and scene segmented by the DeepSSS. The results verified that the DeepSSS’ segmentation resembled that of humans. This is a new kind of result that was enabled by semantic analysis, which was impossible by just using low-level features of videos."
  tags: ["JournalofInformationScience", "Understanding", "NLP"]
  id: 23

- authors: "장영진, 김학수(강원대학교), 김진태(NCSOFT), 왕지현(NCSOFT), 이충희(NCSOFT)"
  title: "듀얼 포인터 네트워크 디코더를 이용한 정답 후보군 탐지 시스템"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "정답 후보군 탐지 모델은 최근 활발히 진행되고 있는 질의-응답 데이터 수집 연구의 선행이 되는 연구로 특정 질문에 대한 정답을 주어진 단라에서 추출하는 작업을 말한다. 제안 모델은 포인터 네트워크 디코더를 통하여 기존의 순차 레이블링 모델에서 처리할 수 없었던 정담이 겹치는 문제애 대해서 해결할 수 있게 되었다. 그리고 독립된 두 개의 포인터 네트워크 디코더를 사용함으로써, 단일 포인터 네트워크로 처리할 수 없었던 정답의 탐지가 가능하게 되었다."
  tags: ["2019한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 24

- authors: "장영진, 김학수(강원대학교), 지혜성(NCSOFT), 이충희(NCSOFT)"
  title: "‘질문-단락’간 주의 집중을 이용한 검색 모델 재순위화 방법"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "검색 모델은 색인된 문서 내에서 입력과 유사한 문서를 검색하는 시스템이다. 최근에는 기계독해 모델과 통합하여 질문에 대한 답을 검색 모델의 결과에서 찾는 연구가 진행되고 있다. 위의 통합 모델이 좋은 결과를 내기 위해서는 검색 모델의 높은 성능이 요구된다. 따라서 본 논문에서는 검색 모델의 성능을 보완해 줄 수 있는 재순위화 모델을 제안한다. 검색 모델의 결과 후보를 일괄적으로 입력받고 '질문-단락' 간 주의 집중을계산하여 재순위화 한다. 실험 결과 P@1 기준으로 기존 검색 모델 성능 대비 5.58%의 성능 향상을 보였다."
  tags: ["2019한글및한국어정보처리학술대회", "Search", "NLP"]
  id: 25

- authors: "이현구, 장영진(강원대학교), 김진태(NCSOFT), 왕지현(NCSOFT), 신동훈(NCSOFT), 김학수(강원대학교)"
  title: "추가 데이터 및 도메인 적응을 위한 기계독해 질의 생성"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "기계독해 모델에 새로운 도메인을 적용하기 위해서는 도메인에 맞는 데이터가 필요하다. 그러나 추가 데이터 구축은 많은 비용이 발생한다. 사람이 직접 구축한 데이터 없이 적용하기 위해서는 자동 추가 데이터 확보, 도메인 적응의 문제를 해결해야한다. 추가 데이터 확보의 경우 번역, 질의 생성의 방법으로 연구가 진행되었다. 그러나 도메인 적응을 위해서는 새로운 정답 유형에 대한 질의가 필요하며 이를 위해서는 정답 후보 추출, 추출된 정답 후보로 질의를 생성해야한다. 본 논문에서는 이러한 문제를 해결하기 위해 듀얼 포인터 네트워크 기반 정답 후보 추출 모델로 정답 후보를 추출하고, 포인터 제너레이터 기반 질의 생성 모델로 새로운 데이터를 생성하는 방법을 제안한다. 실험 결과 추가 데이터 확보의 경우 KorQuAD, 경제, 금융 도메인의 데이터에서 모두 성능 향상을 보였으며, 도메인 적응 실험에서도 새로운 도메인의 문맥만을 이용해 데이터를 생성했을 때 기존 도메인과 다른 도메인에서 모두 기계독해 성능 향상을 보였다."
  tags: ["2019한글및한국어정보처리학술대회", "Search", "NLP"]
  id: 26

- authors: "소찬호(고려대), 왕지현(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT), 강재우(고려대)"
  title: "대화 시스템의 개체 생략 복원을 위한 유효 발화문 인식"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "본 논문은 대화 시스템인 챗봇의 성능 향상을 위한 생략 복원 기술의 정확률을 올리기 위한 유효 발화문 인식 모델을 제안한다. 생략 복원 기술은 챗봇 사용자의 현재 발화문의 생략된 정보를 이전 발화문으로부터 복원하는 기술이다. 유효 발화문 인식 모델은 현재 발화문의 생략된 정보를 보유한 이전 발화문을 인식하는 역할을 수행한다. 유효 발화문 인식 모델은 BERT 기반 이진 분류 모델이며, 사용된 BERT 모델은 한국어 문서를 기반으로 새로 학습된 한국어 사전 학습 BERT 모델이다. 사용자의 현재 발화문과 이전 발화문들의 토큰 임베딩을 한국어 BERT를 통해 얻고, CNN 모델을 이용하여 각 토큰의 지역적인 정보를 추출해서 발화문 쌍의 표현 정보를 구해 해당 이전 발화문에 생략된 개체값이 있는지를 판단한다. 제안한 모델의 효과를 검증하기 위해 유효 발화문 인식 모델에서 유효하다고 판단한 이전 발화문만을 생략 복원 모델에 적용한 결과, 생략 복원 모델의 정확률이 약 5% 정도 상승한 것을 확인하였다."
  tags: ["2019한글및한국어정보처리학술대회", "Dialogue", "NLP"]
  id: 27

- authors: "정재환(스탠포드대학교), 김동준(NCSOFT), 이우철(NCSOFT), 이연수(NCSOFT)"
  title: "어휘 유사 문장 판별을 위한 BERT모델의 학습자료 구축"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "본 논문은 어휘가 비슷한 문장들을 효과적으로 분류하는 BERT 기반 유사 문장 분류기의 학습 자료 구성 방법을 제안한다. 기존의 유사 문장 분류기는 문장의 의미와 상관 없이 각 문장에서 출현한 어휘의 유사도를 기준으로 분류하였다. 이는 학습 자료 내의 유사 문장 쌍들이 유사하지 않은 문장 쌍들보다 어휘 유사도가 높기 때문이다. 따라서, 본 논문은 어휘 유사도가 높은 유사 의미 문장 쌍들과 어휘 유사도가 높지 않은 의미 문장 쌍들을 학습 자료에 추가하여 BERT 유사 문장 분류기를 학습하여 전체 분류 성능을 크게 향상시켰다. 이는 문장의 의미를 결정짓는 단어들과 그렇지 않은 단어들을 유사 문장 분류기가 학습하였기 때문이다. 제안하는 학습 데이터 구축 방법을 기반으로 학습된 BERT 유사 문장 분류기들의 학습된 self-attention weight들을 비교 분석하여 BERT 내부에서 어떤 변화가 발생하였는지 확인하였다."
  tags: ["2019한글및한국어정보처리학술대회", "Data", "NLP"]
  id: 28

- authors: "김진태(KNU), 최기현(KNU), 김학수(KNU), 왕지현(NCSOFT)"
  title: "포인터 네트워크와 자가 주의집중 방법을 이용한 정답 후보군 탐지 시스템"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "정답 후보군 탐지 시스템은 주어진 문단을 이용해 질의을 생성할 때 정답으로 사용이 가능한 정답 후보군들을 탐지하는 시스템이다. 정답 후보군 탐지 시스템은 질의 생성 시스템의 선행 연구로 굉장히 중요하다. 기존 연구는 주어진 문단에서 사용 가능한 정답 후보군 탐지를 위해 포인터 네트워크를 사용해 정답의 후보군을 탐지하며 단순한 명사를 탐지하는 모델과 구절을 탐지하는 모델을 각각 학습했다. 본 논문은 포인터 네트워크를 이용해 명사와 구절을 하나의 모델로 탐지하는 방법을 제안한다. 추가로 정확한 위치를 찾기 위해 자가 주의 집중 방법을 사용해 성능을 향상시킨 정답 후보군 탐지 시스템을 제안한다. 5,736개 데이터를 사용한 실험에서 제안 모델은 일반적인 포인터 네트워크보다 재현율과 F1 점수에서 우수한 성능을 보였고 단순한 명사와 구절 형태의 정답 후보군을 모두 탐지했다."
  tags: ["2019한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 29

- authors: "장영진(KNU), 김학수(KNU), 왕지현(NCSOFT)"
  title: "검색 모델 후처리를 위한 트랜스포머 기반 질의 유형 분류기"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "검색 모델은 색인된 문서 내에서 입력과 유사한 문서를 검색하는 시스템이다. 최근 검색 모델을 기계독해 시스템에 적용하는 연구가 활발해지면서 검색 모델의 성능은 중요한 문제로 대두되고 있다. 이 문제를 해결하기 위해 재순위화 같은 검색 모델의 후처리 연구가 진행되고 있으며, 본 논문에서는 검색 모델의 후처리 모듈에 사용되는 모델을 제안한다. 제안 모델은 질의를 입력받아 질의 유형을 반환하는 문장 분류모델이며, 주의 집중 시퀀스-투-시퀀스 모델 구조에 트랜스포머를 적용하여 구현했다. 10개의 질의 유형분류에 대해 Micro F1 score 기준 86.39%의 성능을 보였다."
  tags: ["2019한글및한국어정보처리학술대회", "Search", "NLP"]
  id: 30

- authors: "Jintae Kim(KNU), Hyeon-Gu Lee(KNU), Harksoo Kim(KNU), Yeonsoo Lee(NCSOFT), Young-Gil Kim(ETRI)"
  title: "Two-Step Training and Mixed Encoding-Decoding for Implementing a Generative Chatbot with a Small Dialogue Corpus"
  conf: "Proceedings of 2IS&NLG 2018"
  year: 2018
  abstract: "Generative chatbot models based on sequence-to-sequence networks can generate natural conversation interactions if a huge dialogue corpus is used as training data. However, except for a few languages such as English and Chinese, it remains difficult to collect a large dialogue corpus. To address this problem, we propose a chatbot model using a mixture of words and syllables as encoding-decoding units. In addition, we propose a two-step training method, involving pre-training using a large non-dialogue corpus and re-training using a small dialogue corpus. In our experiments, the mixture units were shown to help reduce out-of-vocabulary (OOV) problems. Moreover, the two-step training method was effective in reducing grammatical and semantical errors in responses when the chatbot was trained using a small dialogue corpus (533,997 sentence pairs)."
  tags: ["2IS&NLG2018", "Dialogue", "NLP"]
  id: 31

- authors: "김시형(KNU), 김진태(KNU), 김학수(KNU), 최맹식(NCSOFT)"
  title: "질의 확장 및 재순위화를 이용한 기계독해용 검색 모델"
  conf: "2018 한국소프트웨어종합학술대회"
  year: 2018
  abstract: "최근 기계독해 분야는 SQuAD와 같은 챌린지에서 사람을 뛰어 넘는 성능을 보이고 있다. 그러나 이 성능은 문맥 검색 모델이 정확하게 문맥을 검색했을 때의 성능이다. 따라서 문맥을 정확하게 검색 할 수 있는 검색 모델이 필수적이고 중요하다. 본 논문에서는 문맥 검색 모델을 위해 적합성 피드백과 클러스터기반 언어 모델을 사용하여 문맥을 검색하고, 검색한 문맥을 합성곱 신경망을 사용하여 재순위화 하는 모델을 제안한다. 본 논문에서 제안한 검색 모델은 MRR, Precision@k에서 높은 성능을 보였다."
  tags: ["2018한국소프트웨어종합학술대회", "Search", "NLP"]
  id: 32

- authors: "이현구(KNU), 김진태(KNU), 최맹식(NCSOFT), 김학수(KNU)"
  title: "기계독해 기반 질의응답 챗봇"
  conf: "2018 한글 및 한국어 정보처리 학술대회"
  year: 2018
  abstract: "챗봇은 사람과 기계가 자연어로 된 대화를 주고받는 시스템이다. 최근 대화형 인공지능 비서 시스템이 상용화되면서 일반적인 대화와 질의응답을 함께 처리해야할 필요성이 늘어나고 있다. 본 논문에서는 기계독해 기반 질의응답과 Transformer 기반 자연어 생성 모델을 함께 사용하여 하나의 모델에서 일반적인 대화와 질의응답을 함께 하는 기계독해 기반 질의응답 챗봇을 제안한다. 제안 모델은 기계독해 모델에 일반대화를 판단하는 옵션을 추가하여 기계독해를 하면서 자체적으로 문장을 분류하고, 기계독해 결과를 통해 자연어로 된 문장을 생성한다. 실험 결과 일반적인 대화 문장과 질의를 높은 성능으로 구별하면서 기계독해의 성능은 유지하였고 자연어 생성에서도 분류에 맞는 응답을 생성하였다."
  tags: ["2018한글및한국어정보처리학술대회", "Dialogue", "NLP"]
  id: 33

- authors: "김민(스탠포드대), 변증현(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT)"
  title: "Multi-channel CNN을 이용한 한국어 감성분석"
  conf: "2018 한글 및 한국어 정보처리 학술대회"
  year: 2018
  abstract: "본 논문은 한국어 문장의 형태소, 음절, 자소를 동시에 각자 다른 합성곱층을 통과시켜 문장의 감성을 분류하는 Multi-channel CNN을 제안한다. 오타를 포함하는 구어체 문장들의 경우에 형태소 기반 CNN으로 추출 할 수 없는 특징들을 음절이나 자소에서 추출 할 수 있다. 한국어 감성분석에 형태소 기반 CNN이 많이 쓰이지만, 본 논문의 Multi-channel CNN 모델은 형태소, 음절, 자소를 동시에 고려하여 더 정확하게 문장의 감성을 분류한다. 본 논문이 제안하는 모델이 형태소 기반 CNN보다 야구 댓글 데이터에서는 약 4.8%, 영화 리뷰 데이터에서는 약 1.3% 더 정확하게 문장의 감성을 분류하였다."
  tags: ["2018한글및한국어정보처리학술대회", "Understanding", "NLP"]
  id: 34

- authors: "이현구(KNU), 김학수(KNU), 이연수(NCSOFT)"
  title: "GF-Net: 자질 선별을 통한 고성능 기계독해"
  conf: "2018 한국컴퓨터종합학술대회"
  year: 2018
  abstract: "기계독해는 주어진 문맥을 기계가 이해하고 관련된 질의에 대해 답을 하는 질의응답 모델이다. 기계독해 모델은 최근 많은 연구를 통해 인코딩, 상호 집중, 응답 추출 3단계로 정착되었다. 기존의 연구는 상호집중 단계를 연구하여 문맥과 질의간의 상호 관계를 찾는데 집중됐지만 인코더 및 응답 추출을 향상 시키는 연구는 부족하였다. 본 논문은 인코더 및 응답 추출의 성능을 향상시키기 위해 품사, 의존 구문 태그, 개체명 등의 자질을 사용하며, 이러한 자질을 효과적으로 반영하기 위한 자질 게이트 기반 자질 선별 방법을 제안한다. SQuAD(Stanford Question Answering Dataset)를 사용한 실험에서 제안 모델은 이전의 대표적인 모델보다 높은 성능(Exact Match: 81.5%, F1-score: 87.6%)을 보였다."
  tags: ["2018한국컴퓨터종합학술대회", "Understanding", "NLP"]
  id: 35

- authors: "김진태(KNU), 김학수(KNU), 최맹식(NCSOFT), 이연수(NCSOFT), 권오욱(ETRI), 김영길(ETRI)"
  title: "비지도 사전 학습을 이용한 한국어 채팅 시스템"
  conf: "2018 한국컴퓨터종합학술대회"
  year: 2018
  abstract: "채팅 시스템은 사람과 컴퓨터가 자연어를 사용하여 대화를 하는 시스템이다. 생성기반 채팅 모델은 발화-응답 쌍의 데이터를 학습하여, 사용자의 발화에 적합한 응답을 생성하는 모델이다. 단어들을 생성하기 때문에 다양한 응답을 할 수 있는 장점이 있으나, 잘못된 단어를 생성하여 문법에 맞지 않는 문장을 생성하는 단점이 존재한다. 본 논문은 생성 모델에서의 단점을 해결하고자 대량의 일반 문장을 사전 학습하여 문법에 맞는 문장 생성능력을 향상시키고, 채팅 데이터를 통해 대화 능력을 학습하는 채팅 시스템을 제안한다. 134,038 채팅 문장 쌍을 사용한 실험에서 제안 모델은 사전 학습을 사용하지 않는 모델보다 높은 성능(ROUGE-L: 0.4920, ROUGE-1: 0.5043, ROUGE-2: 0.3193, BLEU: 0.5267)을 보였다."
  tags: ["2018한국컴퓨터종합학술대회", "Dialogue", "NLP"]
  id: 36

- authors: "이용혁(NCSOFT), 조남현(NCSOFT)"
  title: "PhonMatchNet: Phoneme-Guided Zero-Shot Keyword Spotting for User-Defined Keywords"
  conf: "INTERSPEECH 2023"
  year: 2023
  abstract: "This study presents a novel zero-shot user-defined keyword spotting model that utilizes the audio-phoneme relationship of the keyword to improve performance. Unlike the previous approach that estimates at utterance level, we use both utterance and phoneme level information. Our proposed method comprises a two-stream speech encoder architecture, selfattention-based pattern extractor, and phoneme-level detection loss for high performance in various pronunciation environments. Based on experimental results, our proposed model outperforms the baseline model and achieves competitive performance compared with full-shot keyword spotting models. Our proposed model significantly improves the EER and AUC across all datasets, including familiar words, proper nouns, and indistinguishable pronunciations, with an average relative improvement of 67% and 80%, respectively"
  tags: ["INTERSPEECH2023","Speech", "Keyword spotting", "Zero-shot", "AI"]
  id: 37

- authors: "김글빛(NCSOFT), 조남현(NCSOFT)"
  title: "Focus-attention-enhanced Crossmodal Transformer with Metric Learning for Multimodal Speech Emotion Recognition"
  conf: "INTERSPEECH 2023"
  year: 2023
  abstract: "Recognizing emotions in speech is essential for improving human-computer interactions, which require understanding and responding to the users’ emotional states. Integrating multiple modalities, such as speech and text, enhances the performance of speech emotion recognition systems by providing a varied source of emotional information. In this context, we propose a model that enhances cross-modal transformer fusion by applying focus attention mechanisms to align and combine the salient features of two different modalities, namely, speech and text. The analysis of the disentanglement of the emotional representation various multiple embedding spaces using deep metric learning confirmed that our method shows enhanced emotion recognition performance. Furthermore, the proposed approach was evaluated on the IEMOCAP dataset. Experimental results demonstrated that our model achieves the best performance among other relevant multimodal speech emotion recognition systems"
  tags: ["INTERSPEECH2023", "Speech", "Emotion recognition", "Multi-modal", "AI"]
  id: 38

- authors: "조남현(NCSOFT), 김선민(NCSOFT), 강요셉(NCSOFT), 김희만(NCSOFT)"
  title: "Fast Enrollable Streaming Keyword Spotting System: Training and Inference using a Web Browser"
  conf: "INTERSPEECH 2023"
  year: 2023
  abstract: "When a keyword spotting system is deployed on heavily personalized platforms such as digital humans, a few issues occur such as 1) a lack of training data when registering userdefined keywords, 2) a desire to reduce computation and minimize latency, and 3) the inability to immediately train and test the keyword-spotting model. We address the issues through 1) a keyword-spotting system based on a speech embedding model, 2) streamable system with duplicate computations removed, and 3) real-time inference in a web browser using WebAssembly."
  tags: ["INTERSPEECH2023", "Speech", "Keyword spotting", "AI"]
  id: 39

- authors: "임종화(NCSOFT), 김민재(NCSOFT)"
  title: "Style-Guided Inference of Transformer for High-resolution Image Synthesis"
  conf: "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (2023)"
  year: 2023
  abstract: "Transformer is eminently suitable for auto-regressive image synthesis which predicts discrete value from the past values recursively to make up full image.Especially, combined with vector quantised latent representation, the state-of-the-art auto-regressive transformer displays realistic high-resolution images. However, sampling the latent code from discrete probability distribution makes the output unpredictable. Therefore, it requires to generate lots of diverse samples to acquire desired outputs.To alleviate the process of generating lots of samples repetitively, in this article, we propose to take a desired output, a style image, as an additional condition without re-training the transformer. To this end, our method transfers the style to a probability constraint to re-balance the prior, thereby specifying the target distribution instead of the original prior. Thus, generated samples from the re-balanced prior have similar styles to reference style.In practice, we can choose either an image or a category of images as an additional condition. In our qualitative assessment, we show that styles of majority of outputs are similar to the input style."
  tags: ["WACV2023", "Vision", "AI"]
  id: 40

- authors: "전성호, 장주용, 박성범(NCSOFT)"
  title: "Learnable Human Mesh Triangulation for 3D Human Pose and Shape Estimation"
  conf: "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (2023)"
  year: 2023
  abstract: "Compared to joint position, the accuracy of joint rotation and shape estimation has received relatively little attention in the skinned multi-person linear model (SMPL)-based human mesh reconstruction from multi-view images. The work in this field is broadly classified into two categories. The first approach performs joint estimation and then produces SMPL parameters by fitting SMPL to resultant joints. The second approach regresses SMPL parameters directly from the input images through a convolutional neural network (CNN)-based model. However, these approaches suffer from the lack of information for resolving the ambiguity of joint rotation and shape reconstruction and the difficulty of network learning. To solve the aforementioned problems, we propose a two-stage method. The proposed method first estimates the coordinates of mesh vertices through a CNN-based model from input images, and acquires SMPL parameters by fitting the SMPL model to the estimated vertices. Estimated mesh vertices provide sufficient information for determining joint rotation and shape, and are easier to learn than SMPL parameters. According to experiments using Human3.6M and MPI-INF-3DHP datasets, the proposed method significantly outperforms the previous works in terms of joint rotation and shape estimation, and achieves competitive performance in terms of joint location estimation."
  tags: ["WACV2023", "Vision", "AI"]
  id: 41

- authors: "강승윤, 이민현, 김민재(NCSOFT), 심현정"
  title: "HybridMatch: Semi-supervised Facial Landmark Detection via Hybrid Heatmap Representations"
  conf: "IEEE Access 2023"
  year: 2023
  abstract: "Facial landmark detection is an essential task in face-processing techniques. Traditional methods, however, require expensive pixel-level labels. Semi-supervised facial landmark detection has been explored as an alternative, but previous approaches only focus on training-oriented issues (e.g., noisy pseudo-labels in semi-supervised learning), neglecting task-oriented issues (i.e., the quantization error in landmark detection). We argue that semi-supervised landmark detectors should resolve the two technical issues simultaneously. Through a simple experiment, we found that task- and training-oriented solutions may negatively influence each other, thus eliminating their negative interactions is important. To this end, we devise a new heatmap regression framework via hybrid representation, namely HybridMatch. We utilize both 1-D and 2-D heatmap representations. Here, the 1-D and 2-D heatmaps help alleviate the taskoriented and training-oriented issues, respectively. To exploit the advantages of our hybrid representation, we introduce curriculum learning; relying more on the 2-D heatmap at the early training stage and gradually increasing the effects of the 1-D heatmap. By resolving the two issues simultaneously, we can capture more precise landmark points than existing methods with only a few annotated data. Extensive experiments show that HybridMatch achieves state-of-the-art performance on three benchmark datasets, especially showing 26.3% NME improvement over the existing method in the 300-W full set at 5% data ratio. Surprisingly, our method records a comparable performance, 5.04 (challenging set in the 300-W) to the fully-supervised facial landmark detector 5.03. The remarkable performance of HybridMatch shows its potential as a practical alternative to the fully-supervised model."
  tags: ["IEEE Access 2023", "Vision", "AI"]
  id: 42

- authors: "배한빈(NCSOFT), 주영선(NCSOFT)"
  title: "Enhancement of Pitch Controllability using Timbre-Preserving Pitch Augmentation in FastPitch"
  conf: "INTERSPEECH 2022"
  year: 2022
  abstract: "The recently developed pitch-controllable text-to-speech (TTS) model, i.e. FastPitch, was conditioned for the pitch contours. However, the quality of the synthesized speech degraded considerably for pitch values that deviated significantly from the average pitch; i.e. the ability to control pitch was limited. To address this issue, we propose two algorithms to improve the robustness of FastPitch. First, we propose a novel timbre-preserving pitch-shifting algorithm for natural pitch augmentation. Pitch-shifted speech samples sound more natural when using the proposed algorithm because the speaker's vocal timbre is maintained. Moreover, we propose a training algorithm that defines FastPitch using pitch-augmented speech datasets with different pitch ranges for the same sentence. The experimental results demonstrate that the proposed algorithms improve the pitch controllability of FastPitch."
  tags: ["INTERSPEECH2022", "Speech", "TTS", "AI"]
  id: 43

- authors: "배재성(NCSOFT), 양진혁(NCSOFT), 박태준(NCSOFT), 주영선(NCSOFT)"
  title: "Hierarchical and Multi-Scale Variational Autoencoder for Diverse and Natural Non-Autoregressive Text-to-Speech"
  conf: "INTERSPEECH 2022"
  year: 2022
  abstract: "This paper proposes a hierarchical and multi-scale variational autoencoder-based non-autoregressive text-to-speech model (HiMuV-TTS) to generate natural speech with diverse speaking styles. Recent advances in non-autoregressive TTS (NAR-TTS) models have significantly improved the inference speed and robustness of synthesized speech. However, the diversity of speaking styles and naturalness are needed to be improved. To solve this problem, we propose the HiMuV-TTS model that first determines the global-scale prosody and then determines the local-scale prosody via conditioning on the global-scale prosody and the learned text representation. In addition, we improve the quality of speech by adopting the adversarial training technique. Experimental results verify that the proposed HiMuV-TTS model can generate more diverse and natural speech as compared to TTS models with single-scale variational autoencoders, and can represent different prosody information in each scale."
  tags: ["INTERSPEECH2022", "Speech", "TTS", "AI"]
  id: 44

- authors: "김태우(NCSOFT), 강민수(NCSOFT), 이경훈(NCSOFT)"
  title: "Adversarial Multi-Task Learning for Disentangling Timbre and Pitch in Singing Voice Synthesis"
  conf: "INTERSPEECH 2022"
  year: 2022
  abstract: "Recently, deep learning-based generative models have been introduced to generate singing voices. One approach is to predict the parametric vocoder features consisting of explicit speech parameters. This approach has the advantage that the meaning of each feature is explicitly distinguished. Another approach is to predict mel-spectrograms for a neural vocoder. However, parametric vocoders have limitations of voice quality and the mel-spectrogram features are difficult to model because the timbre and pitch information are entangled. In this study, we propose a singing voice synthesis model with multi-task learning to use both approaches -- acoustic features for a parametric vocoder and mel-spectrograms for a neural vocoder. By using the parametric vocoder features as auxiliary features, the proposed model can efficiently disentangle and control the timbre and pitch components of the mel-spectrogram. Moreover, a generative adversarial network framework is applied to improve the quality of singing voices in a multi-singer model. Experimental results demonstrate that our proposed model can generate more natural singing voices than the single-task models, while performing better than the conventional parametric vocoder-based model."
  tags: ["INTERSPEECH2022", "Speech", "Singing voice synthesis", "AI"]
  id: 45

- authors: "Seyoung Lee, Jiye Lee, Jehee Lee(NCSOFT)"
  title: "Learning Virtual Chimeras by Dynamic Motion Reassembly"
  conf: "SIGGRAPH Asia 2022"
  year: 2022
  abstract: "The Chimera is a mythological hybrid creature composed of different animal parts. The chimera’s movements are highly dependent on the spatial and temporal alignments of its composing parts. In this paper, we present a novel algorithm that creates and animates chimeras by dynamically reassembling source characters and their movements. Our algorithm exploits a two-network architecture: part assembler and dynamic controller. The part assembler is a supervised learning layer that searches for the spatial alignment among body parts, assuming that the temporal alignment is provided. The dynamic controller is a reinforcement learning layer that learns robust control policy for a wide variety of potential temporal alignments. These two layers are tightly intertwined and learned simultaneously. The chimera animation generated by our algorithm is energy efficient and expressive in terms of describing weight shifting, balancing, and full-body coordination. We demonstrate the versatility of our algorithm by generating the motor skills of a large variety of chimeras from limited source characters."
  tags: ["SIGGRAPH Asia 2022", "Graphics", "AI"]
  id: 46

- authors: "정하림, 오명석, 이성환, 양철종(NCSOFT)"
  title: "Neural Architecture Adaptation for Object Detection by Searching Channel Dimensions and Mapping Pre-trained Parameters"
  conf: "International Conference on Pattern Recognition (ICPR) (2022)"
  year: 2022
  abstract: "Most object detection frameworks use backbone architectures originally designed for image classification, conventionally with pre-trained parameters on ImageNet. However, image classification and object detection are essentially different tasks and there is no guarantee that the optimal backbone for classification is also optimal for object detection. Recent neural architecture search (NAS) research has demonstrated that automatically designing a backbone specifically for object detection helps improve the overall accuracy. In this paper, we introduce a neural architecture adaptation method that can optimize the given backbone for detection purposes, while still allowing the use of pre-trained parameters. We propose to adapt both the micro- and macro-architecture by searching for specific operations and the number of layers, in addition to the output channel dimensions of each block. It is important to find the optimal channel depth, as it greatly affects the feature representation capability and computation cost. We conduct experiments with our searched backbone for object detection and demonstrate that our backbone outperforms both manually designed and searched state-of-the-art backbones on the COCO dataset."
  tags: ["ICPR2022", "Vision", "AI"]
  id: 47

- authors: "이건희(NCSOFT), 임종화(NCSOFT), 김찬란(NCSOFT), 김민재(NCSOFT)"
  title: "StyLandGAN: A StyleGAN based Landscape Image Synthesis using Depth-map"
  conf: "Computer Vision and Pattern Recognition Conference Workshop (CVPR) (2022)" 
  year: 2022
  abstract: "Despite recent success in conditional image synthesis, prevalent input conditions such as semantics and edges are not clear enough to express ‘Linear (Ridges)’ and ‘Planar (Scale)’ representations. To address this problem, we propose a novel framework StyLandGAN, which synthesizes desired landscape images using a depth map which has higher expressive power. Our StyleLandGAN is extended from the unconditional generation model to accept input conditions. We also propose a ’2-phase inference’ pipeline which generates diverse depth maps and shifts local parts so that it can easily reflect user’s intend. As a comparison, we modified the existing semantic image synthesis models to accept a depth map as well. Experimental results show that our method is superior to existing methods in quality, diversity, and depth-accuracy."
  tags: ["CVPR Workshop 2022", "Vision", "AI"]
  id: 48

- authors: "공다영, 이준석, 김만진, 하성종(NCSOFT), 조민수"
  title: "Future Transformer for Long-term Action Anticipation"
  conf: "Computer Vision and Pattern Recognition Conference (CVPR) (2022)"
  year: 2022
  abstract: "The task of predicting future actions from a video is crucial for a real-world agent interacting with others. When anticipating actions in the distant future, we humans typically consider long-term relations over the whole sequence of actions, i.e., not only observed actions in the past but also potential actions in the future. In a similar spirit, we propose an end-to-end attention model for action anticipation, dubbed Future Transformer (FUTR), that leverages global attention over all input frames and output tokens to predict a minutes-long sequence of future actions. Unlike the previous autoregressive models, the proposed method learns to predict the whole sequence of future actions in parallel decoding, enabling more accurate and fast inference for longterm anticipation. We evaluate our method on two standard benchmarks for long-term action anticipation, Breakfast and 50 Salads, achieving state-of-the-art results."
  tags: ["CVPR2022", "Vision", "AI"]
  id: 49

- authors: "Inseok Oh, Seungeun Rho, Sangbin Moon, Seongho Son, Hyoil Lee, Jinyun Chung "
  title: "Creating Pro-Level AI for a Real-Time Fighting Game Using Deep Reinforcement Learning"
  conf: "IEEE Transactions on Games, Volume: 14, Issue: 2, June 2022, pp. 212 - 220 "
  year: 2022
  abstract: "Reinforcement learning (RL) combined with deep neural networks has performed remarkably well in many genres of games recently. It has surpassed human-level performance in fixed game environments and turn-based two-player board games. However, to the best of our knowledge, current research has yet to produce a result that has surpassed human-level performance in modern complex fighting games. This is due to the inherent difficulties with real-time fighting games, including: vast action spaces, action dependencies, and imperfect information. We overcame these challenges and made 1v1 battle AI agents for the commercial game Blade and Soul . The trained agents competed against five professional gamers and achieved a winning rate of 62%. This article presents a practical RL method that includes a novel self-play curriculum and data skipping techniques. Through the curriculum, three different styles of agents were created by reward shaping and were trained against each other. Additionally, this article suggests data-skipping techniques that could increase data efficiency and facilitate explorations in vast spaces. Since our method can be generally applied to all two-player competitive games with vast action spaces, we anticipate its application to game development including level design and automated balancing."
  tags: ["IEEE Transactions on Games 2022", "Reinforcement Learning", "Deep learning", "fighting game", "self-play curriculum learning", "AI"]
  id: 50

- authors: "Jinyun Chung, Seungeun Rho"
  title: "Reinforcement Learning in Action: Creating Arena Battle AI for 'Blade & Soul'"
  conf: "Game Developers Conference (GDC) (2022) (AI Summit)"
  year: 2022
  abstract: "The NCSOFT team applied reinforcement learning to create an AI for the arena 1v1 battle in 'Blade & Soul', a global MMORPG. The AI agents participated in the 2018 'Blade & Soul' Tournament World Championship as blind matches and played against three top professional players from across the globe. The AI had 3 wins and 4 loses - an impressive showing against professional players. In this session, the NCSOFT team will will share their experiences on how they built pro-level AI agents."
  tags: ["GDC2022","AI Summit","Reinforcement Learning", "AI"]
  id: 51

- authors: "Inseok Oh, Jinhyung Ahn"
  title: "Multi-Agent Reinforcement Learning Invades MMORPG: 'Lineage Clone Wars'"
  conf: "Game Developers Conference (GDC) (2022) (AI Summit)"
  year: 2022
  abstract: "Lineage is a massively multiplayer online role-playing game played by millions of players around the world. For the first time ever, we developed two types of multi-agent AI battle content in the Lineage universe using reinforcement learning. Clone Wars and Rookies vs. Veterans offer a chance for users to experience an exhilarating battle against AI opponents. In the future, reinforcement learning will be applied in new ways to create more MMORPG content where users can engage in multiplayer battles with AIs."
  tags: ["GDC2022","AI Summit","Reinforcement Learning", "Multi-agent Reinforcement Learning", "AI"]
  id: 52

- authors: "양진혁(NCSOFT), 배재성(NCSOFT), 박태준(NCSOFT), 김영익(NCSOFT), 조훈영(NCSOFT)"
  title: "GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis"
  conf: "INTERSPEECH 2021"
  year: 2021
  abstract: "Recent advances in neural multi-speaker text-to-speech (TTS) models have enabled the generation of reasonably good speech quality with a single model and made it possible to synthesize the speech of a speaker with limited training data. Fine-tuning to the target speaker data with the multi-speaker model can achieve better quality, however, there still exists a gap compared to the real speech sample and the model depends on the speaker. In this work, we propose GANSpeech, which is a high-fidelity multi-speaker TTS model that adopts the adversarial training method to a non-autoregressive multi-speaker TTS model. In addition, we propose simple but efficient automatic scaling methods for feature matching loss used in adversarial training. In the subjective listening tests, GANSpeech significantly outperformed the baseline multi-speaker FastSpeech and FastSpeech2 models, and showed a better MOS score than the speaker-specific fine-tuned FastSpeech2."
  tags: ["INTERSPEECH2021", "Speech", "TTS", "AI"]
  id: 53

- authors: "박태준(NCSOFT), 배재성(NCSOFT), 배한빈(NCSOFT), 김영익(NCSOFT), 조훈영(NCSOFT)"
  title: "FastPitchFormant: Source-filter based Decomposed Modeling for Speech Synthesis"
  conf: "INTERSPEECH 2021"
  year: 2021
  abstract: "Methods for modeling and controlling prosody with acoustic features have been proposed for neural text-to-speech (TTS) models. Prosodic speech can be generated by conditioning acoustic features. However, synthesized speech with a large pitch-shift scale suffers from audio quality degradation, and speaker characteristics deformation. To address this problem, we propose a feed-forward Transformer based TTS model that is designed based on the source-filter theory. This model, called FastPitchFormant, has a unique structure that handles text and acoustic features in parallel. With modeling each feature separately, the tendency that the model learns the relationship between two features can be mitigated."
  tags: ["INTERSPEECH2021", "Speech", "TTS", "AI"]
  id: 54

- authors: "이경훈(NCSOFT), 김태우(NCSOFT), 배한빈(NCSOFT), 이민지(NCSOFT), 김영익(NCSOFT), 조훈영(NCSOFT)"
  title: "N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement"
  conf: "INTERSPEECH 2021"
  year: 2021
  abstract: "Recently, end-to-end Korean singing voice systems have been designed to generate realistic singing voices. However, these systems still suffer from a lack of robustness in terms of pronunciation accuracy. In this paper, we propose N-Singer, a non-autoregressive Korean singing voice system, to synthesize accurate and pronounced Korean singing voices in parallel. N-Singer consists of a Transformer-based mel-generator, a convolutional network-based postnet, and voicing-aware discriminators. It can contribute in the following ways. First, for accurate pronunciation, N-Singer separately models linguistic and pitch information without other acoustic features. Second, to achieve improved mel-spectrograms, N-Singer uses a combination of Transformer-based modules and convolutional network-based modules. Third, in adversarial training, voicing-aware conditional discriminators are used to capture the harmonic features of voiced segments and noise components of unvoiced segments. The experimental results prove that N-Singer can synthesize a natural singing voice in parallel with a more accurate pronunciation than the baseline model."
  tags: ["INTERSPEECH2021", "Speech", "Music", "Singing voice synthesis", "AI"]
  id: 55

- authors: "배재성(NCSOFT), 박태준(NCSOFT), 주영선(NCSOFT), 조훈영(NCSOFT)"
  title: "Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech"
  conf: "INTERSPEECH 2021"
  year: 2021
  abstract: "In this paper, we propose methods for improving the modeling performance of a Transformer-based non-autoregressive text-to-speech (TNA-TTS) model. Although the text encoder and audio decoder handle different types and lengths of data (i.e., text and audio), the TNA-TTS models are not designed considering these variations. Therefore, to improve the modeling performance of the TNA-TTS model we propose a hierarchical Transformer structure-based text encoder and audio decoder that are designed to accommodate the characteristics of each module. For the text encoder, we constrain each self-attention layer so the encoder focuses on a text sequence from the local to the global scope. Conversely, the audio decoder constrains its self-attention layers to focus in the reverse direction, i.e., from global to local scope. Additionally, we further improve the pitch modeling accuracy of the audio decoder by providing sentence and word-level pitch as conditions. Various objective and subjective evaluations verified that the proposed method outperformed the baseline TNA-TTS."
  tags: ["INTERSPEECH2021", "Speech", "TTS", "AI"]
  id: 56
