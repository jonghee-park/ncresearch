- authors: "Donghyun Kim, Youbin Ahn, Wongyu Kim, Chanhee Lee, Kyungchan Lee, Kyong‐Ho Lee, Jeonguk Kim, Donghoon Shin(NCSOFT), Yeonsoo Lee(NCSOFT)"
  title: "Persona Expansion with Commonsense Knowledge for Diverse and Consistent Response Generation"
  conf: "The 17th Conference of the European Chapter of the Association for Computational Linguistics(EACL). (2023)"
  year: 2023
  abstract: ""
  tags: ["EACL2023", "generation"]
  id: 0

- authors: "Donghyun Kim, Youbin Ahn, Chanhee Lee, Wongyu Kim, Kyong‐Ho Lee, Donghoon Shin(NCSOFT), Yeonsoo Lee(NCSOFT)"
  title: "Concept-based Persona Expansion for Improving Diversity of Persona-Grounded Dialogue"
  conf: "The 17th Conference of the European Chapter of the Association for Computational Linguistics(EACL). (2023)"
  year: 2023
  abstract: ""
  tags: ["EACL2023", "dialogue"]
  id: 1

- authors: "Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo Lee(NCSOFT), Dong-Hoon Shin(NCSOFT), Seungryong Kim, Heuiseok Lim"
  title: "Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge"
  conf: "Proceedings of the AAAI Conference on Artificial Intelligence(AAAI). (2022)"
  year: 2022
  abstract: "Humans usually have conversations by making use of prior knowledge about a topic and background information of the people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive information, and thus they have a limitation in generating the utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge. To evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and GPT-2 as well as transformer-based models. We assess their generation abilities with automatic scores and conduct human evaluations for qualitative results. We examine whether the model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we show that the utterances of our data are constructed with the proper knowledge and persona through grounding quality assessment."
  tags: ["AAAI2022", "dialogue"]
  id: 2

- authors: "Sanghak Lee, Seungmin Seo, Byungkook Oh, Kyong-Ho Lee, Donghoon Shin(NCSOFT),Yeonsoo Lee(NCSOFT)"
  title: "Active Learning for Knowledge Graph Schema Expansion"
  conf: "IEEE Transactions on Knowledge and Data Engineering (TKDE), Vol. 32, Issue 12, pp. 5610-5620"
  year: 2022
  abstract: ""
  tags: ["TKDE"]
  id: 3

- authors: "Jungwoo Lim(Korea Univ), Myugnhoon Kang(Korea Univ), Yuna Hur(Korea Univ), Seung Won Jeong(Korea Univ), Jinsung Kim(Korea Univ), Yoonna Jang(Korea Univ), Dongyub Lee(NAVER), Hyesung Ji(NCSOFT), DongHoon Shin(NCSOFT), Seungryong Kim(Korea Univ) and Heuiseok Lim(Korea Univ)"
  title: "You Truly Understand What I Need: Intellectual and Friendly Dialogue Agents grounding Knowledge and Persona"
  conf: "The 2022 Conference on Empirical Methods in Natural Language Processing(EMNLP) (2022)"
  year: 2022
  abstract: "To build a conversational agent that interacts fluently with humans, previous studies blend knowledge or personal profile into the pre-trained language model. However, the model that considers knowledge and persona at the same time is still limited, leading to hallucination and a passive way of using personas. We propose an effective dialogue agent that grounds external knowledge and persona simultaneously. The agent selects the proper knowledge and persona to use for generating the answers with our candidate scoring implemented with a poly-encoder. Then, our model generates the utterance with lesser hallucination and more engagingness utilizing retrieval augmented generation with knowledge-persona enhanced query. We conduct experiments on the personaknowledge chat and achieve state-of-the-art performance in grounding and generation tasks on the automatic metrics. Moreover, we validate the answers from the models regarding hallucination and engagingness through human evaluation and qualitative results. We show our retriever’s effectiveness in extracting relevant documents compared to the other previous retrievers, along with the comparison of multiple candidate scoring methods. Code is available at https://github.com/dlawjddn803/INFO"
  tags: ["EMNLP2022", "dialogue"]
  id: 4

- authors: "Seonil Son (NCSOFT), Junsoo Park (NCSOFT), Jeong-in Hwang (NCSOFT), Junghwa Lee (NCSOFT), Hyungjong Noh (NCSOFT), Yeonsoo Lee (NCSOFT)"
  title: "HaRiM+: Evaluating Summary Quality with Hallucination Risk"
  conf: "AACL 2022"
  year: 2022
  abstract: "One of the challenges of developing a summarization model arises from the difficulty in measuring the factual inconsistency of the generated text. In this study, we reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries. We propose a reference-free metric, HaRiM+, which only requires an off-the-shelf summarization model to compute the hallucination risk based on token likelihoods. Deploying it requires no additional training of models or ad-hoc modules, which usually need alignment to human judgments. For summary-quality estimation, HaRiM+ records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits the use of summarization models, facilitates the progress of both automated evaluation and generation of summary."
  tags: ["AACL2022"]
  id: 5

- authors: "Hojun Cho (KAIST), Dohee Kim (KAIST), Seungwoo Ryu (KAIST), ChaeHun Park (KAIST), Hyungjong Noh (NCSOFT), Jeong-in Hwang (NCSOFT), Minseok Choi (KAIST), Edward Choi (KAIST), Jaegul Choo (KAIST)"
  title: "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model"
  conf: "The 2022 Conference on Empirical Methods in Natural Language Processing(EMNLP) (2022)"
  year: 2022
  abstract: "Style control, content preservation, and fluency determine the quality of text style transfer models. To train on a nonparallel corpus, several existing approaches aim to deceive the style discriminator with an adversarial loss. However, adversarial training significantly degrades fluency compared to the other two metrics. In this work, we explain this phenomenon using energy-based interpretation, and leverage a pretrained language model to improve fluency. Specifically, we propose a novel approach which applies the pretrained language model to the text style transfer framework by restructuring the discriminator and the model itself, allowing the generator and the discriminator to also take advantage of the power of the pretrained model. We evaluated our model on three public benchmarks GYAFC, Amazon, and Yelp and achieved state-of-the-art performance on the overall metrics."
  tags: ["EMNLP2022"]
  id: 6

- authors: "Eunhwan Park(JNU), Jong-Hyeon Lee(NCSOFT), Jeon Dong Hyeon(NAVER), Seonhoon Kim(NAVER), INHO KANG(NAVER) and Seung-Hoon Na(JNU)"
  title: "SISER: Semantic-Infused Selective Graph Reasoning for Fact Verification"
  conf: "Proceedings of the 29th International Conference on Computational Linguistics. (COLING) (2022)"
  year: 2022
  abstract: "This study proposes Semantic-Infused SElective Graph Reasoning (SISER) for fact verification, which newly presents semantic-level graph reasoning and injects its reasoning-enhanced representation into other
  types of graph-based and sequence-based reasoning methods. SISER combines three reasoning types: 1) semantic-level graph reasoning, which uses a semantic graph from evidence sentences, whose nodes are elements of a triple – <Subject, Verb, Object>, 2)“semantic-infused” sentence-level “selective” graph reasoning, which combine semanticlevel and sentence-level representations and perform graph reasoning in a selective manner using the node selection mechanism, and 3) sequence reasoning, which concatenates all evidence sentences and performs attentionbased reasoning. Experiment results on a large-scale dataset for Fact Extraction and VERification (FEVER) show that SISER outperforms the previous graph-based approaches and achieves state-of-the-art performance."
  tags: ["COLING2022"]
  id: 7

- authors: "이정, 서민택, 나승훈, 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "자기지도학습 기반 음성 언어 모델을 이용한 자소 단위의 한국어 음성 인식"
  conf: "2022 한국소프트웨어종합학술대회"
  year: 2022
  abstract: "최근 다양한 산업 전반에서 자동 음성 인식(Automatic Speech Recognition)을 활용한 음성 기반의 인터페이스가 적용됨에 따라 높은 수준의 정확도를 보이는 음성 인식 기술에 대한 필요성이 점차 증대되고 있다. 하지만 음성 인식 분야에 대규모 사전 학습 모델을 활용하기 위해서는 음성 데이터와 함께 음성 전사 텍스트 데이터가 주석된 데이터(Labeled Data)가 필수적이나 대규모의 주석 데이터 구축에는 큰 비용이 소모된다는 단점이 존재한다. 따라서 본 논문에서는 주석 데이터에 대한 의존성을 줄이기 위하여 자기지도학습(Self-supervised Learning)에 기반한 사전 학습 음성 언어 모델을 바탕으로 한국어 음성 인식 모델을 구성하고 성능을 보인다."
  tags: ["2022한국소프트웨어종합학술대회"]
  id: 8

- authors: "서민택, 나승훈, 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "한국어 음성인식 오류 교정을 위한 N-Best 결과 기반 생성 모델"
  conf: "2022 한국소프트웨어종합학술대회"
  year: 2022
  abstract: "성능 향상을 위한 많은 노력에도 불구하고 현재 Automatic Speech Recognition(ASR) 모델은 완벽하지 않기 때문에 실제 서비스에서 오류는 나타날 수밖에 없다. 서비스 품질 향상을 위해 이러한 오류 발생을 후처리를 통해 교정하려는 많은 노력이 진행되고 있다. 그러나 이러한 오류 유형중 고유명사 인식에서 오류가 발생하는 경우가 적지 않은데, 이러한 오류는 문장 자체로 본다면 정상이라 단일 단서로 교정하기가 어렵다. 이런 오류를 교정하기 위해서는 최상의 결과만을 활용하는 대신 상위 결과를 추가적으로 활용한다면 단서가 늘어나 올바른 단어로 교정할 확률이 증가한다. 따라서 본 논문에서는 생성 모델과 N-Best 결과를 이용한 간소화된 Ensemble 방법을 통해 교정 결과의 향상을 확인한다."
  tags: ["2022한국소프트웨어종합학술대회"]
  id: 9

- authors: "이정, 서민택, 나승훈(전북대학교), 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "N-Best Re-ranking에 기반한 한국어 음성 인식 성능 개선"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "자동 음성 인식(Automatic Speech Recognition) 혹은 Speech-to-Text(STT)는 컴퓨터가 사람이 말하는 음성 언어를 텍스트 데이터로 전환하는 일련의 처리나 기술 등을 일컫는다. 음성 인식 기술이 다양한 산업 전반에 걸쳐 적용됨에 따라 높은 수준의 정확도와 더불어 다양한 분야에 적용할 수 있는 음성 인식 기술에 대한 필요성이 점차 증대되고 있다. 다만 한국어 음성 인식의 경우 기존 선행 연구에 비해 예사말/높임말의 구분이나 어미, 조사 등의 인식에 어려움이 있어 음성 인식 결과 후처리를 통한 성능 개선이 중요하다. 따라서 본 논문에서는 N-Best 음성 인식 결과가 구성되었을 때 Re-ranking을  통해 한국어 음성 인식의 성능을 개선하는 모델을 제안한다."
  tags: ["2022한글및한국어정보처리학술대회"]
  id: 10

- authors: "서민택, 나승훈(전북대학교), 나민수(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT)"
  title: "문법성 품질 예측에 기반한 음성 인식 오류 교정"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "딥러닝의 발전 이후, 다양한 분야에서는 딥러닝을 이용해 이전에 어려웠던 작업들을 해결하여 사용자에게 편의성을 제공하고 있다. 하지만 아직 딥러닝을 통해 이상적인 서비스를 제공하는 데는 어려움이 있다. 특히, 음성 인식 작업에서 음성 양식에서 이용 방안에 대하여 다양성을 제공해주는 음성을 텍스트로 전환하는 Speech-To-Text(STT)은 문장 결과가 이상치에 달하지 못해 오류가 나타나게 된다. 본 논문에서는 STT 결과 보정을 문법 교정으로 치환하여 종단에서 올바른 토큰들을 조합하여 성능 향상을 하기 위해 각 토큰 별 품질 평가를 진행하는 모델을 한국어에서 적용하고 성능의 향상을 확인한다."
  tags: ["2022한글및한국어정보처리학술대회"]
  id: 11

- authors: "정민지(NCSOFT), 이새벽(NCSOFT), 김영준(NCSOFT), 허철훈(NCSOFT), 이충희(NCSOFT)"
  title: "오픈 도메인 질의응답을 위한 질문-구절의 밀집 벡터 표현 연구"
  conf: "2022 한글 및 한국어 정보처리 학술대회"
  year: 2022
  abstract: "질문에 답하기 위해 관련 구절을 검색하는 기술은 오픈 도메인 질의응답의 검색 단계를 위해 필요하다. 전통적인 방법은 정보 검색 기법인 빈도-역문서 빈도(TF-IDF) 기반으로 희소한 벡터 표현을 활용하여 구절을 검색한다. 하지만 희소 벡터 표현은 벡터 길이가 길 뿐만 아니라, 질문에 나오지 않는 단어나 토큰을 검색하지 못한다는 취약점을 가진다. 밀집 벡터 표현 연구는 이러한 취약점을 개선하고 있으며 대부분의 연구가 영어 데이터셋을 학습한 것이다. 따라서, 본 연구는 한국어 데이터셋을 학습한 밀집 벡터 표현을 연구하고 여러 가지 부정 샘플(negative sample) 추출 방법을 도입하여 전이 학습한 모델 성능을 비교 분석한다. 또한, 대화 응답 선택 태스크에서 밀집 검색에 활용한 순위 재지정 상호작용 레이어를 추가한 실험을 진행하고 비교 분석한다. 밀집 벡터 표현 모델을 학습하는 것이 도전적인 과제인만큼 향후에도 다양한 시도가 필요할 것으로 보인다."
  tags: ["2022한글및한국어정보처리학술대회"]
  id: 12

- authors: "Byung-Chull Bae(hongik univ.) Suji Jang(hongik univ), Youngjune Kim(NCSOFT), Seyoung Park(NCSOF)"
  title: "A Preliminary Survey on Story Interestingness: Focusing on Cognitive and Emotional Interest"
  conf: "ICIDS 2021"
  year: 2021
  abstract: "Story interestingness is of great importance in narrative understanding and generation. In this paper, based on the outlined literature review, we present our incipient framework for measuring story interestingness, consisting of two factors - cognitive interest and emotional interest. The cognitive factors include four components - goal, novelty, inference, and schema violation. The emotional aspects contain four elements - empathy, external emotions, humor, and outcome valence."
  tags: ["ICIDS2021"]
  id: 13

- authors: "정영준 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "비지도 기계 번역을 이용한 한국어 채팅체 문체 변환"
  conf: "2021 한국컴퓨터종합학술대회"
  year: 2021
  abstract: "문체 변환(style transfer)은 소스 문체(source style)로 쓰여진 텍스트가 주어지면 내용(content)을 유지하면서 타겟 문체(target style)의 텍스트를 생성하는 작업이다. 일반적으로 내용은 불변성(invariance), 문체는 가변성(variance)이라고 가정하여 텍스트의 문체를 변환하게 된다. 하지만, 채팅체의 경우 내용과 문체의 경계가 모호한 특성을 가지기 때문에 분리에 어려움이 있어 기존의 문체 변환 모델로 학습이 잘 되지 않는 문제가 있다. 본 논문에서는 비지도 기계 번역(unsupervised machine translation)을 이용한 문체 변환 모델을 사용하여 채팅체를 문어체로 변환하는 방법을 제안한다. 또한, 변환된 결과를 활용하여 문체 변환에 사용될 수 있는 문체 간 단어 변환 사전을 구축할 수 있음을 보인다."
  tags: ["2021한국컴퓨터종합학술대회", "문체변환"]
  id: 14

- authors: "민주 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "채팅체-문어체 스타일 변환 병렬 코퍼스 자동 구축"
  conf: "2021 한국컴퓨터종합학술대회"
  year: 2021
  abstract: "인터넷 채팅체로 쓰여진 문장은 문어체 문장과 달리 신조어 및 축약어가 쓰이며 문체 또한 일반적인 문어체 또는 구어체와 상이하다. 따라서 인터넷 채팅체를 기존 문어체 기반 자연어처리 시스템에서 이용하기 위해서는 채팅체-문어체 스타일 변환 기술이 필요하며, 이를 위해서 구어체-문어체로 이루어진 병렬 코퍼스를 구축할 필요가 있다. 본 논문에서는 채팅체 문장을 문어체로 변환한 문장 쌍 병렬 코퍼스를 Round-Trip Translation 기법을 이용하여 자동으로 구축하고, 자동으로 구축된 병렬 코퍼스 중에 부정확한 문장 쌍을 자동으로 필터링하는 방법을 제안한다. 또한 구축된 병렬 코퍼스를 검증하기 위해 구축된 병렬 코퍼스를 이용하여 자동으로 채팅체-문어체 변환 사전을 구축하였다."
  tags: ["2021한국컴퓨터종합학술대회"]
  id: 15

- authors: "배장성 (강원대학교), 이창기 (강원대학교), 황정인 (NCSOFT), 노형종 (NCSOFT)"
  title: "마스크 언어 모델 기반 비병렬 한국어 텍스트 스타일 변환"
  conf: "2021 한글및한국어정보처리 학술대회"
  year: 2021
  abstract: "텍스트 스타일 변환은 입력 스타일(source style)로 쓰여진 텍스트의 내용(content)을 유지하며 목적 스타일(target style)의 텍스트로 변환하는 문제이다. 텍스트 스타일 변환을 시퀀스 간 변환 문제(sequence-to-sequence)로 보고 기존 기계학습 모델을 이용해 해결할 수 있지만, 모델 학습에 필요한 각 스타일에 대응되는 병렬 말뭉치를 구하기 어려운 문제점이 있다. 따라서 최근에는 비병렬 말뭉치를 이용해 텍스트 스타일 변환을 수행하는 방법들이 연구되고 있다. 이 연구들은 주로 인코더-디코더 구조의 생성 모델을 사용하기 때문에 입력 문장이 가지고 있는 내용이 누락되거나 다른 내용의 문장이 생성될 수 있는 문제점이 있다. 본 논문에서는 마스크 언어 모델(masked language model)을 이용해 입력 텍스트의 내용을 유지하면서 원하는 스타일로 변경할 수 있는 텍스트 스타일 변환 방법을 제안하고 한국어 긍정-부정, 채팅체-문어체 변환에 적용한다."
  tags: ["2021한글및한국어정보처리학술대회"]
  id: 16

- authors: "박진솔(서울대학교), 최맹식(NCSOFT), Andrew Matteson(NCSOFT), 이충희(NCSOFT)"
  title: "생략복원을 위한 ELECTRA 기반 모델 최적화 연구"
  conf: "2021 한글및한국어정보처리 학술대회"
  year: 2021
  abstract: "한국어에서는 문장 내의 주어나 목적어가 자주 생략된다. 자연어 처리에서 이러한 문장을 그대로 사용하는 것은 정보 부족으로 인한 문제 난이도 상승으로 귀결된다. 생략복원은 텍스트에서 생략된 부분을 이전 문구에서 찾아서 복원해 주는 기술이며, 본 논문은 생략된 주어를 복원하는 방법에 대한 연구이다. 본 논문에서는 기존에 생략복원에 사용되지 않았던 다양한 입력 형태를 시도한다. 또한, 출력 레이어로는 finetuning layer(Linear, Bi-LSTM, MultiHeadAttention)와 생략복원 태스크 형태(BIO tagging, span prediction)의 다양한 조합을 실험한다. 국립국어원 무형 대용어 복원 말뭉치를 기반으로 생략복원이 불필요한 네거티브 샘플을 추가하여 ELECTRA 기반의 딥러닝 생략복원 모델을 학습시키고, 생략복원에 최적화된 조합을 검토한다."
  tags: ["2021한글및한국어정보처리학술대회"]
  id: 17

- authors: "Hyonsu Choe(NCSOFT), Jiyoon Han(YU), Hyejin Park(YU), Tae Hwan Oh(YU), Hansaem Kim(YU)"
  title: "Building Korean Abstract Meaning Representation Corpus"
  conf: "Proceedings of DMR 2020"
  year: 2020
  abstract: "To explore the potential sembanking in Korean and ways to represent the meaning of Korean sentences, this paper reports on the process of applying Abstract Meaning Representation to Korean, a semantic representation framework that has been studied in wide range of languages, and its output: the Korean AMR corpus. The corpus which is constructed so far is a size of 1,253 sentences and its raw texts are from ExoBrain Corpus, a state-led R&D project on language AI. This paper also analyzes the result in both qualitative and quantitative manners, proposing discussions for further development."
  tags: ["ProceedingsofDMR2020"]
  id: 18

- authors: "신승우 (NCSOFT), 오주민 (NCSOFT), 노형종 (NCSOFT), 이연수 (NCSOFT)"
  title: "Sent2dl : 기술논리 SROIQ 기반 기호적 문장 의미 표상에 분산 표상 더하기"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "기존의 자연어 의미 표상 방법은 크게 나눠보았을 때 두 가지가 있다. 첫 번째로, 전통적인 기호 기반 의미 표상 방법론이다. 이 방법론들은 논리적이고 해석가능하다는 장점이 있으나, 구축에 시간이 많이 들고 정작 기호 자체의 의미를 더욱 미시적으로 파악하기 어렵다는 단점이 있었다. 반면, 최근 대두된 분산 표상의 경우 단어 하나하나의 의미는 상대적으로 잘 파악하는 반면, 문장 등의 복잡한 구조의 의미를 나타내는 데 있어 상대적으로 약한 측면을 보이며 해석가능하지 않다는 단점이 있다. 본 논문에서는 이 둘의 장점을 섞어서 서로의 단점을 보완하는 새로운 의미 표상을 제안하였으며, 이 표상이 유의미하게 문장의 의미를 담고 있음을 비지도 문장 군집화 문제를 통해 간접적으로 보였다."
  tags: ["2020한글및한국어정보처리학술대회"]
  id: 19

- authors: "이진우(NCSOFT), 최맹식(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT)"
  title: "의존 구문 분석에 손실 함수가 미치는 영향: 한국어 Left-To-Right Parser를 중심으로"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "본 연구는 딥 러닝 기반 의존 구문 분석에서, 학습에 적용하는 손실 함수에 따른 성능을 평가하였다. Pointer Network를 이용한 Left-To-Right 모델을 총 세 가지의 손실 함수(Maximize Golden Probability, Cross Entropy, Local Hinge)를 이용하여 학습시켰다. 그 결과 LH 손실 함수로 학습한 모델이 선행 연구와 같이 MGP 손실 함수로 학습한 것에 비해 UAS/LAS가 각각 0.86%p/0.87%p 상승하였으며, 특히 의존 거리가 먼 경우에 대하여 분석 성능이 크게 향상됨을 확인하였다. 딥러닝 의존 구문 분석기를 구현할 때 학습 모델과 입력 표상뿐만 아니라 손실 함수 역시 중요하게 고려되어야 함을 보였다."
  tags: ["2020한글및한국어정보처리학술대회"]
  id: 20

- authors: "최현수(NCSOFT), 민진우, 나승훈(전북대학교), 김한샘(연세대학교)"
  title: "국어 의미 자원 구축 및 의미 파싱을 위한 Korean AMR 데이터 자동 증강"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "본 연구에서는 한국어 의미 표상 자원 구축과 의미 파싱 성능 향상을 위한 데이터 자동 증강 방법을 제안하고 수동 구축 결과 대비 자동 변환 정확도를 보인다. 지도 학습 기반의 AMR 파싱 모델이 유의미한 성능에 도달하려면 대량의 주석 데이터가 반드시 필요하다. 본 연구에서는 기성 언어 분석 기술 또는 기존에 구축된 말뭉치의 주석 정보를 바탕으로 Semi-AMR 데이터를 변환해내는 알고리즘을 제시하며, 자동 변환 결과는 Gold-standard 데이터에 대해 Smatch F1 0.46의 일치도를 보였다. 일정 수준 이상의 정확도를 보이는 자동 증강 데이터는 주석 프로젝트에 소요되는 비용을 경감시키는 데에 활용될 수 있다."
  tags: ["2020한글및한국어정보처리학술대회"]
  id: 21

- authors: "이민호(NCSOFT), 최맹식(NCSOFT), 김정아(NCSOFT), 이충희(NCSOFT), 김보희(NCSOFT), 오효정(전북대학교), 이연수(NCSOFT)"
  title: "키워드 추출용 구묶음 데이터 구축 및 개선 방법 연구"
  conf: "2020 한글및한국어정보처리 학술대회"
  year: 2020
  abstract: "구묶음은 문장을 겹치지 않는 문장 구성 성분으로 나누는 과정으로, 구묶음 방법에 따라 구문분석, 관계추출 등 다양한 하위 태스크에 사용할 수 있다. 본 논문에서는 문장의 키워드를 추출하기 위한 구묶음 방식을 제안하고, 키워드 단위 구묶음 데이터를 구축하기 위한 가이드라인을 제작하였다. 해당 가이드라인을 적용하여 구축한 데이터와 BERT 기반의 모델을 이용하여 학습 및 평가를 통해 구축된 데이터의 품질을 측정하여 78점의 F1점수를 얻었다. 이후 패턴 통일, 형태소 표시 여부 등 다양한 개선 방법의 적용 및 재실험을 통해 가이드라인의 개선 방향을 제시한다."
  tags: ["2020한글및한국어정보처리학술대회"]
  id: 22

- authors: "Hyesung Ji(NCSOFT), Danial Hooshyar, Kuekyeng Kim, and Heuiseok Lim (Korea univ)"
  title: "A semantic-based video scene segmentation using a deep neural network"
  conf: "Journal of Information Science 45(6)"
  year: 2019
  abstract: "Video scene segmentation is very important research in the field of computer vision, because it helps in efficient storage, indexing and retrieval of videos. Achieving this kind of scene segmentation cannot be done by just calculating the similarity of low-level features presented in the video; high-level features should also be considered to achieve a better performance. Even though much research has been conducted on video scene segmentation, most of these studies failed to semantically segment a video into scenes. Thus, in this study, we propose a Deep-learning Semantic-based Scene-segmentation model (called DeepSSS) that considers image captioning to segment a video into scenes semantically. First, the DeepSSS performs shot boundary detection by comparing colour histograms and then employs maximum-entropy-applied keyframe extraction. Second, for semantic analysis, using image captioning that benefits from deep learning generates a semantic text description of the keyframes. Finally, by comparing and analysing the generated texts, it assembles the keyframes into a scene grouped under a semantic narrative. That said, DeepSSS considers both low- and high-level features of videos to achieve a more meaningful scene segmentation. By applying DeepSSS to data sets from MS COCO for caption generation and evaluating its semantic scene-segmentation task results with the data sets from TRECVid 2016, we demonstrate quantitatively that DeepSSS outperforms other existing scene-segmentation methods using shot boundary detection and keyframes. What’s more, the experiments were done by comparing scenes segmented by humans and scene segmented by the DeepSSS. The results verified that the DeepSSS’ segmentation resembled that of humans. This is a new kind of result that was enabled by semantic analysis, which was impossible by just using low-level features of videos."
  tags: ["JournalofInformationScience"]
  id: 23

- authors: "장영진, 김학수(강원대학교), 김진태(NCSOFT), 왕지현(NCSOFT), 이충희(NCSOFT)"
  title: "듀얼 포인터 네트워크 디코더를 이용한 정답 후보군 탐지 시스템"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "정답 후보군 탐지 모델은 최근 활발히 진행되고 있는 질의-응답 데이터 수집 연구의 선행이 되는 연구로 특정 질문에 대한 정답을 주어진 단라에서 추출하는 작업을 말한다. 제안 모델은 포인터 네트워크 디코더를 통하여 기존의 순차 레이블링 모델에서 처리할 수 없었던 정담이 겹치는 문제애 대해서 해결할 수 있게 되었다. 그리고 독립된 두 개의 포인터 네트워크 디코더를 사용함으로써, 단일 포인터 네트워크로 처리할 수 없었던 정답의 탐지가 가능하게 되었다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 24

- authors: "장영진, 김학수(강원대학교), 지혜성(NCSOFT), 이충희(NCSOFT)"
  title: "‘질문-단락’간 주의 집중을 이용한 검색 모델 재순위화 방법"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "검색 모델은 색인된 문서 내에서 입력과 유사한 문서를 검색하는 시스템이다. 최근에는 기계독해 모델과 통합하여 질문에 대한 답을 검색 모델의 결과에서 찾는 연구가 진행되고 있다. 위의 통합 모델이 좋은 결과를 내기 위해서는 검색 모델의 높은 성능이 요구된다. 따라서 본 논문에서는 검색 모델의 성능을 보완해 줄 수 있는 재순위화 모델을 제안한다. 검색 모델의 결과 후보를 일괄적으로 입력받고 '질문-단락' 간 주의 집중을계산하여 재순위화 한다. 실험 결과 P@1 기준으로 기존 검색 모델 성능 대비 5.58%의 성능 향상을 보였다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 25

- authors: "이현구, 장영진(강원대학교), 김진태(NCSOFT), 왕지현(NCSOFT), 신동훈(NCSOFT), 김학수(강원대학교)"
  title: "추가 데이터 및 도메인 적응을 위한 기계독해 질의 생성"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "기계독해 모델에 새로운 도메인을 적용하기 위해서는 도메인에 맞는 데이터가 필요하다. 그러나 추가 데이터 구축은 많은 비용이 발생한다. 사람이 직접 구축한 데이터 없이 적용하기 위해서는 자동 추가 데이터 확보, 도메인 적응의 문제를 해결해야한다. 추가 데이터 확보의 경우 번역, 질의 생성의 방법으로 연구가 진행되었다. 그러나 도메인 적응을 위해서는 새로운 정답 유형에 대한 질의가 필요하며 이를 위해서는 정답 후보 추출, 추출된 정답 후보로 질의를 생성해야한다. 본 논문에서는 이러한 문제를 해결하기 위해 듀얼 포인터 네트워크 기반 정답 후보 추출 모델로 정답 후보를 추출하고, 포인터 제너레이터 기반 질의 생성 모델로 새로운 데이터를 생성하는 방법을 제안한다. 실험 결과 추가 데이터 확보의 경우 KorQuAD, 경제, 금융 도메인의 데이터에서 모두 성능 향상을 보였으며, 도메인 적응 실험에서도 새로운 도메인의 문맥만을 이용해 데이터를 생성했을 때 기존 도메인과 다른 도메인에서 모두 기계독해 성능 향상을 보였다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 26

- authors: "소찬호(고려대), 왕지현(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT), 강재우(고려대)"
  title: "대화 시스템의 개체 생략 복원을 위한 유효 발화문 인식"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "본 논문은 대화 시스템인 챗봇의 성능 향상을 위한 생략 복원 기술의 정확률을 올리기 위한 유효 발화문 인식 모델을 제안한다. 생략 복원 기술은 챗봇 사용자의 현재 발화문의 생략된 정보를 이전 발화문으로부터 복원하는 기술이다. 유효 발화문 인식 모델은 현재 발화문의 생략된 정보를 보유한 이전 발화문을 인식하는 역할을 수행한다. 유효 발화문 인식 모델은 BERT 기반 이진 분류 모델이며, 사용된 BERT 모델은 한국어 문서를 기반으로 새로 학습된 한국어 사전 학습 BERT 모델이다. 사용자의 현재 발화문과 이전 발화문들의 토큰 임베딩을 한국어 BERT를 통해 얻고, CNN 모델을 이용하여 각 토큰의 지역적인 정보를 추출해서 발화문 쌍의 표현 정보를 구해 해당 이전 발화문에 생략된 개체값이 있는지를 판단한다. 제안한 모델의 효과를 검증하기 위해 유효 발화문 인식 모델에서 유효하다고 판단한 이전 발화문만을 생략 복원 모델에 적용한 결과, 생략 복원 모델의 정확률이 약 5% 정도 상승한 것을 확인하였다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 27

- authors: "정재환(스탠포드대학교), 김동준(NCSOFT), 이우철(NCSOFT), 이연수(NCSOFT)"
  title: "어휘 유사 문장 판별을 위한 BERT모델의 학습자료 구축"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "본 논문은 어휘가 비슷한 문장들을 효과적으로 분류하는 BERT 기반 유사 문장 분류기의 학습 자료 구성 방법을 제안한다. 기존의 유사 문장 분류기는 문장의 의미와 상관 없이 각 문장에서 출현한 어휘의 유사도를 기준으로 분류하였다. 이는 학습 자료 내의 유사 문장 쌍들이 유사하지 않은 문장 쌍들보다 어휘 유사도가 높기 때문이다. 따라서, 본 논문은 어휘 유사도가 높은 유사 의미 문장 쌍들과 어휘 유사도가 높지 않은 의미 문장 쌍들을 학습 자료에 추가하여 BERT 유사 문장 분류기를 학습하여 전체 분류 성능을 크게 향상시켰다. 이는 문장의 의미를 결정짓는 단어들과 그렇지 않은 단어들을 유사 문장 분류기가 학습하였기 때문이다. 제안하는 학습 데이터 구축 방법을 기반으로 학습된 BERT 유사 문장 분류기들의 학습된 self-attention weight들을 비교 분석하여 BERT 내부에서 어떤 변화가 발생하였는지 확인하였다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 28

- authors: "김진태(KNU), 최기현(KNU), 김학수(KNU), 왕지현(NCSOFT)"
  title: "포인터 네트워크와 자가 주의집중 방법을 이용한 정답 후보군 탐지 시스템"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "정답 후보군 탐지 시스템은 주어진 문단을 이용해 질의을 생성할 때 정답으로 사용이 가능한 정답 후보군들을 탐지하는 시스템이다. 정답 후보군 탐지 시스템은 질의 생성 시스템의 선행 연구로 굉장히 중요하다. 기존 연구는 주어진 문단에서 사용 가능한 정답 후보군 탐지를 위해 포인터 네트워크를 사용해 정답의 후보군을 탐지하며 단순한 명사를 탐지하는 모델과 구절을 탐지하는 모델을 각각 학습했다. 본 논문은 포인터 네트워크를 이용해 명사와 구절을 하나의 모델로 탐지하는 방법을 제안한다. 추가로 정확한 위치를 찾기 위해 자가 주의 집중 방법을 사용해 성능을 향상시킨 정답 후보군 탐지 시스템을 제안한다. 5,736개 데이터를 사용한 실험에서 제안 모델은 일반적인 포인터 네트워크보다 재현율과 F1 점수에서 우수한 성능을 보였고 단순한 명사와 구절 형태의 정답 후보군을 모두 탐지했다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 29

- authors: "장영진(KNU), 김학수(KNU), 왕지현(NCSOFT)"
  title: "검색 모델 후처리를 위한 트랜스포머 기반 질의 유형 분류기"
  conf: "2019 한글및한국어정보처리 학술대회"
  year: 2019
  abstract: "검색 모델은 색인된 문서 내에서 입력과 유사한 문서를 검색하는 시스템이다. 최근 검색 모델을 기계독해 시스템에 적용하는 연구가 활발해지면서 검색 모델의 성능은 중요한 문제로 대두되고 있다. 이 문제를 해결하기 위해 재순위화 같은 검색 모델의 후처리 연구가 진행되고 있으며, 본 논문에서는 검색 모델의 후처리 모듈에 사용되는 모델을 제안한다. 제안 모델은 질의를 입력받아 질의 유형을 반환하는 문장 분류모델이며, 주의 집중 시퀀스-투-시퀀스 모델 구조에 트랜스포머를 적용하여 구현했다. 10개의 질의 유형분류에 대해 Micro F1 score 기준 86.39%의 성능을 보였다."
  tags: ["2019한글및한국어정보처리학술대회"]
  id: 30

- authors: "Jintae Kim(KNU), Hyeon-Gu Lee(KNU), Harksoo Kim(KNU), Yeonsoo Lee(NCSOFT), Young-Gil Kim(ETRI)"
  title: "Two-Step Training and Mixed Encoding-Decoding for Implementing a Generative Chatbot with a Small Dialogue Corpus"
  conf: "Proceedings of 2IS&NLG 2018"
  year: 2018
  abstract: "Generative chatbot models based on sequence-to-sequence networks can generate natural conversation interactions if a huge dialogue corpus is used as training data. However, except for a few languages such as English and Chinese, it remains difficult to collect a large dialogue corpus. To address this problem, we propose a chatbot model using a mixture of words and syllables as encoding-decoding units. In addition, we propose a two-step training method, involving pre-training using a large non-dialogue corpus and re-training using a small dialogue corpus. In our experiments, the mixture units were shown to help reduce out-of-vocabulary (OOV) problems. Moreover, the two-step training method was effective in reducing grammatical and semantical errors in responses when the chatbot was trained using a small dialogue corpus (533,997 sentence pairs)."
  tags: ["2IS&NLG2018"]
  id: 31

- authors: "김시형(KNU), 김진태(KNU), 김학수(KNU), 최맹식(NCSOFT)"
  title: "질의 확장 및 재순위화를 이용한 기계독해용 검색 모델"
  conf: "2018 한국소프트웨어종합학술대회"
  year: 2018
  abstract: "최근 기계독해 분야는 SQuAD와 같은 챌린지에서 사람을 뛰어 넘는 성능을 보이고 있다. 그러나 이 성능은 문맥 검색 모델이 정확하게 문맥을 검색했을 때의 성능이다. 따라서 문맥을 정확하게 검색 할 수 있는 검색 모델이 필수적이고 중요하다. 본 논문에서는 문맥 검색 모델을 위해 적합성 피드백과 클러스터기반 언어 모델을 사용하여 문맥을 검색하고, 검색한 문맥을 합성곱 신경망을 사용하여 재순위화 하는 모델을 제안한다. 본 논문에서 제안한 검색 모델은 MRR, Precision@k에서 높은 성능을 보였다."
  tags: ["2018한국소프트웨어종합학술대회"]
  id: 32

- authors: "이현구(KNU), 김진태(KNU), 최맹식(NCSOFT), 김학수(KNU)"
  title: "기계독해 기반 질의응답 챗봇"
  conf: "2018 한글 및 한국어 정보처리 학술대회"
  year: 2018
  abstract: "챗봇은 사람과 기계가 자연어로 된 대화를 주고받는 시스템이다. 최근 대화형 인공지능 비서 시스템이 상용화되면서 일반적인 대화와 질의응답을 함께 처리해야할 필요성이 늘어나고 있다. 본 논문에서는 기계독해 기반 질의응답과 Transformer 기반 자연어 생성 모델을 함께 사용하여 하나의 모델에서 일반적인 대화와 질의응답을 함께 하는 기계독해 기반 질의응답 챗봇을 제안한다. 제안 모델은 기계독해 모델에 일반대화를 판단하는 옵션을 추가하여 기계독해를 하면서 자체적으로 문장을 분류하고, 기계독해 결과를 통해 자연어로 된 문장을 생성한다. 실험 결과 일반적인 대화 문장과 질의를 높은 성능으로 구별하면서 기계독해의 성능은 유지하였고 자연어 생성에서도 분류에 맞는 응답을 생성하였다."
  tags: ["2018한글및한국어정보처리학술대회"]
  id: 33

- authors: "김민(스탠포드대), 변증현(NCSOFT), 이충희(NCSOFT), 이연수(NCSOFT)"
  title: "Multi-channel CNN을 이용한 한국어 감성분석"
  conf: "2018 한글 및 한국어 정보처리 학술대회"
  year: 2018
  abstract: "본 논문은 한국어 문장의 형태소, 음절, 자소를 동시에 각자 다른 합성곱층을 통과시켜 문장의 감성을 분류하는 Multi-channel CNN을 제안한다. 오타를 포함하는 구어체 문장들의 경우에 형태소 기반 CNN으로 추출 할 수 없는 특징들을 음절이나 자소에서 추출 할 수 있다. 한국어 감성분석에 형태소 기반 CNN이 많이 쓰이지만, 본 논문의 Multi-channel CNN 모델은 형태소, 음절, 자소를 동시에 고려하여 더 정확하게 문장의 감성을 분류한다. 본 논문이 제안하는 모델이 형태소 기반 CNN보다 야구 댓글 데이터에서는 약 4.8%, 영화 리뷰 데이터에서는 약 1.3% 더 정확하게 문장의 감성을 분류하였다."
  tags: ["2018한글및한국어정보처리학술대회"]
  id: 34

- authors: "이현구(KNU), 김학수(KNU), 이연수(NCSOFT)"
  title: "GF-Net: 자질 선별을 통한 고성능 기계독해"
  conf: "2018 한국컴퓨터종합학술대회"
  year: 2018
  abstract: "기계독해는 주어진 문맥을 기계가 이해하고 관련된 질의에 대해 답을 하는 질의응답 모델이다. 기계독해 모델은 최근 많은 연구를 통해 인코딩, 상호 집중, 응답 추출 3단계로 정착되었다. 기존의 연구는 상호집중 단계를 연구하여 문맥과 질의간의 상호 관계를 찾는데 집중됐지만 인코더 및 응답 추출을 향상 시키는 연구는 부족하였다. 본 논문은 인코더 및 응답 추출의 성능을 향상시키기 위해 품사, 의존 구문 태그, 개체명 등의 자질을 사용하며, 이러한 자질을 효과적으로 반영하기 위한 자질 게이트 기반 자질 선별 방법을 제안한다. SQuAD(Stanford Question Answering Dataset)를 사용한 실험에서 제안 모델은 이전의 대표적인 모델보다 높은 성능(Exact Match: 81.5%, F1-score: 87.6%)을 보였다."
  tags: ["2018한국컴퓨터종합학술대회"]
  id: 35

- authors: "김진태(KNU), 김학수(KNU), 최맹식(NCSOFT), 이연수(NCSOFT), 권오욱(ETRI), 김영길(ETRI)"
  title: "비지도 사전 학습을 이용한 한국어 채팅 시스템"
  conf: "2018 한국컴퓨터종합학술대회"
  year: 2018
  abstract: "채팅 시스템은 사람과 컴퓨터가 자연어를 사용하여 대화를 하는 시스템이다. 생성기반 채팅 모델은 발화-응답 쌍의 데이터를 학습하여, 사용자의 발화에 적합한 응답을 생성하는 모델이다. 단어들을 생성하기 때문에 다양한 응답을 할 수 있는 장점이 있으나, 잘못된 단어를 생성하여 문법에 맞지 않는 문장을 생성하는 단점이 존재한다. 본 논문은 생성 모델에서의 단점을 해결하고자 대량의 일반 문장을 사전 학습하여 문법에 맞는 문장 생성능력을 향상시키고, 채팅 데이터를 통해 대화 능력을 학습하는 채팅 시스템을 제안한다. 134,038 채팅 문장 쌍을 사용한 실험에서 제안 모델은 사전 학습을 사용하지 않는 모델보다 높은 성능(ROUGE-L: 0.4920, ROUGE-1: 0.5043, ROUGE-2: 0.3193, BLEU: 0.5267)을 보였다."
  tags: ["2018한국컴퓨터종합학술대회"]
  id: 36
